---
title: "[Data Engineering] Hadoop 개념 정리"
date: "2022-09-20 17:15:16"
categories: [Data Engineering]
tags: [hadoop]

toc : true
future : true

---

### Hadoop 기본 개념

> Hadoop (High-Availability Distributed Object-Oriented Platform)
> - 자바 소프트웨어 프레임워크로 빅데이터 분산 처리 프레임워크
> - 하나의 컴퓨터가 처리할 일을 여러 대의 컴퓨터가 병렬적으로 처리함으로써 처리속도를 현저히 단축시켜주고 데이터 파일도 분산 저장할 수 있도록 함


### 하둡의 장.단점

**장점**

- 오픈소스로서 비용 부담이 적다.
- 시스템을 중단하지 않고 서버의 증설이 가능하다.
- 저렴한 구축비용과 데이터 처리가 빠르다.
- 배치성 프로세스에 최적화 되어있다.

**단점**
- HDFS에 저장된 데이터를 변경할 수 없다.
- 실시간 데이터에 대해서는 하둡만으로는 부적합하다.
- 기술지원이 좋지 않다.
- 설정할 요소가 많고 복잡하다.

-------

### HDFS(Hadoop Distributed FileSystem)
- 하둡 분산형 파일시스템(HDFS)는 하둡 네트워크에 연결된 기기에 데이터를 저장하는 분산형 파일시스템으로 실시간 처리보다는 배치처리를 목적으로 설계되었다.
- 따라서 작업량이 작거나 빠른 데이터 응답이 필요한 작업에서는 적합하지 않다.

> HDFS의 특징
- 데이터를 블록 단위로 나누어 저장한다. 따라서 큰 데이터를 나누어 저장하므로 단일 디스크 보다 큰 파일도 저장이 가능
ex) 블록단위가 256MB라면 1G파일은 4개의 블록으로 나누어 저장된다.
- 블록에 문제가 생겨 데이터가 손실되는 경우를 막기 위해 HDFS는 각 블록을 복제하여 중복 저장함
- HDFS는 읽기 중심을 목적으로 만들어 졌기 때문에 파일의 수정은 지원하지 않는다. (읽는 속도를 높인다.)
- 맵리듀스(아래에서 나옴)는 HDFS의 데이터의 지역성을 이용해서 처리 속도를 증가시킨다.
  (데이터 처리시 데이터 위치에서 알고리즘을 처리하여 데이터 이동 비용 감소시킴)

> HDFS 구조(Architecture)
- HDFS는 기본적으로 마스터 슬레이브 구조

**마스터/슬레이브(Master/Slave)**
마스터/슬레이브(Master/slave)는 장치나 프로세스(마스터)가 하나 이상의 다른 장치나 프로세스(슬레이브)를 통제하고 통신 허브 역할을 하는 비대칭 통신 및 제어 모델

![image](https://user-images.githubusercontent.com/74512114/202324748-a405231f-5123-482c-857e-c298b23ae7b3.png)

- MapReduce는 일을 어떻게 나눠서 수행하는지를 Master에서 관리
- HDFS는 저장 시 어떻게 분산 저장할 지를 Master에서 관리
- 네임노드는 메타데이터를 가지고 있고, 데이터는 블록 단위로 나누어 데이터노드에 저장
- 데이터를 읽고 쓰려면 사용자는 메타데이터를 가지고 있는 네임노드를 이용

--------------

### 네임노드와 데이터노드의 역할
> 네임노드
1. 메타데이터를 관리
2. 데이터 노드들을 모니터링, 데이터노드들은 3초마다 한 번씩 네임노드에게 하트비트 메시지를 전송함으로써 데이터 노드들의 실행 상태와 용량을 모니터링
3. 블록들을 관리, 만약 특정 데이터 노드에 장애가 발생하면 해당 데이터 노드의 블록을 새로운 데이터 노드로 복제. 또한 용량이 부족한 데이터 노드가 있다면 용량에 여유가 있는 데이터 노드로 블록을 이동시킵니다.
4. 클라이언트의 요청을 처리

**메타데이터**
- 메타데이터는 파일이름, 파일크기, 파일생성시간, 파일접근권한, 파일 소유자 및 그룹 소유자, 파일이 위치한 블록의 정보 등으로 구성

> 데이터 노드
- 데이타노드는 파일을 저장하는 역할을 하며, 이떄 파일은 블록단위로 저장
- 주기적으로 네임노드에 하트비트와 블록리포트를 전달

`하트비트` : 데이터노드의 동작여부를 판단하는데 이용, 네임노드에서는 하트비트가 전달되지 않는
데이터노드는 동작하지 않는 것으로 판단하여 더이상 데이터를 저장하지 않도록 설정한다.

`블록리포트` : 블록의 변경사항을 체크하고, 네임노드의 메타데이터를 갱신한다. 블록파일은 사용자가 설정한 위치(dfs.data.dir)에 저장


- 데이터 노드의 경우 클라이언트가 HDFS에 저장하는 파일의 블록을 데이터 노드 로컬 디스크에 유지하고 분산 처리 작업 발생시 작업을 처리
- 데이터 노드의 상태를 나타내는 정보로 활성상태와 운영상태 확인


**하둡의 동작 흐름**
- 데이터가 들어오면 데이터를 분해,분리 하여 저장
- 데이터를 나눈 후 어느 데이터 노드에 저장 되어있는 기록해 놓는(메타데이터) 필요
-> 네임노드에서 분산을 하고 저장위치를 분배, 그 후 여러개 중에 지정된 데이터 노드에 저장

--------------

### HDFS 파일 사용

![image](https://user-images.githubusercontent.com/74512114/202328125-63941071-e45a-4592-81e9-58b51ac02ba0.png)

> HDFS 파일 읽는 순서
1. open() 명령어를 통해 DistributedFileSystem에 있는 FileSystem의 파일을 연다
2. PRC()를 NameNode를 호출하여 저장되어있는 블록이 저장된 DataNode의 주소를 받는다.
3. DistributedFileSystem은 client가 데이터를 검색할 수 있도록 검색을 지원하는 입력 스트림인 FSDataInputStream를 client에게 준다. 그러면 그것을 통해 찾고자 하는 datanode와 DFSInputStream이 맵핑된다. 그리고 검색후 read() 명령어를 통해 호출을한다.
4. datanode 주소가 저장된 DFSInputStream은 datanode와 연결되고, 데이터는 datanode에서 클라이언트로 가게된다. 이러한 형식으로 반복 read()가 호출하여 파일을 읽는다.
5. 블록 끝에 도달하면 DFSInputStream은 데이터 노드에 대한 열결을 닫고, 다음 블록에 가장 접합한 데이터 노드를 찾는다.
6. 읽기가 마치면 FSDataInputStram에서 close()를 호출한다.


-------

> HDFS Federation
- HDFS Federation은 디렉토리 단위로 네임노드를 등록하여 사용하는 것으로, 파일이 많아짐에 따른 메모리 관리 문제를 해결하기 위해 하둡 v2 부터 지원

ex) /user, /hadoop, /tmp 각각의 디렉토리 단위로 총 3개의 네임노드를 실행, 독립적으로 관리하여 다른 네임 노드에 영향을 주지 않는다.


> HDFS High Availability(고가용성)
- 네임노드에 문제가 발생하면 모든 작업이 중지되고, 파일을 읽거나 쓸수 없게 된다. 하둡 v2에서 이 문제를 해결하기 위해서 HDFS High Availability을 제공
- 이중화된 두대의 서버인 액티브(active) 네임노드와 스탠바이(standby) 네임노드를 이용하여 지원
`엑티브 네임노드` : 네임노드의 역활을 수행
`스탠바이 네임노드` : 액티브 네임노드와 동일한 메타데이터 정보를 유지하다가, 액티브 네임노드에 문제가 발생하면 스탠바이 네임노드가 액티브 네임노드로 동작

<br>

- `액티브 네임노드`에 문제가 발생하는 것을 자동으로 확인하는 것이 어렵기 때문에
보통 `주키퍼`를 이용하여 장애 발생시 자동으로 `스탠바이 네임노드`로 변경될 수 있도록 한다.
- 스탠바이 네임노드는 세컨더리 네임노드의 역할을 동일하게 수행하기 때문에, HDFS를 고가용성 모드로 설정하였을 때는 세컨더리 네임노드를 실행하지 않아도 된다.
- 고가용성 모드에서 세컨더리 네임노드를 실행하면 오류가 발생한다.

`Zookeeper` : 분산 시스템 간의 정보 공유 및 상태 체크, 동기화를 처리하는 프레임워크로 이러한 시스템을 코디네이션 서비스 시스템이라고 한다.

> HDFS safemode
> - safemode는 읽기 전용 상태로 데이터 노드 수정이 불가능하며, 데이터의 추가, 수정, 복제가 일어나지 않는다.
> - 보통 safemode는 노드에 문제가 생겼거나 서버 운영 정비를 위해 설정을 한다.

```
# 세이프 모드 상태 확인
$ hdfs dfsadmin -safemode get
Safe mode is OFF

# 세이프 모드 진입
$ hdfs dfsadmin -safemode enter
Safe mode is ON

# 세이프 모드 해제
$ hdfs dfsadmin -safemode leave
Safe mode is OFF
```

----------------

### 맵리듀스(Map Reduce)
- Goggle MapReduce를 참고해서 Hadoop MapReduce 프레임워크가 만들어짐
- `하둡 분산 파일 시스템(HDFS)`은 대용량 파일을 지리적으로 분산되어 있는 수많은 서버에 저장하는 솔루션이며,
`맵-리듀스`는 분산되어 저장된 대용량 데이터를 병렬로 처리하는 솔루션
- 특정 데이터 노드만 분석하고 결과만 받는 것이 `맵-리듀스` -> 통합분석이 아닌, 개별분석 후 결과를 취합

**Map 단계**
- Map은 분산되어있는 컴퓨터에서 처리
- Map단계에서는 흩어져 있는 데이터를 key, value로 데이터를 묶어준다.
- key는 몇 번째 데이터인지, value는 값을 추출한 정보를 가진다. '빅데이터'가 key라면 value는 빅데이터라는 키가 몇번 나오는지의 숫자.
- key와 value를 구한 후에 통합하기 위해 통합하는 곳(Reduce)으로 보내준다.
-> `Map`은 흩어져 있는 데이터를 Key, Value의 형태의 연관성 있는 데이터 분류로 묶는 작업

**Reduce 단계**
- 최종적인 통합관리를 위해 Reduce를 해주는 것이다.
- ex) [A] key: 빅데이터, value: 5 / [B]: key: 빅데이터, value: 10 일때 `Reduce`는 빅데이터가 총 15번 나왔다고 통합
- Reduce단계는 Map단계의 key를 중심으로 필터링 및 정렬, 하둡에서는 이 Map과 Reduce를 함수를 통해서 구현하고 맵리듀스 잡을 통해 제어
-> `Reduce`는 Filtering과 Sorting을 거쳐 데이터를 추출, Map 작업 중 중복데이터를 제거하고 원하는 데이터를 추출하는 작업


**버전에 따른 MapReduce 차이**
![image](https://user-images.githubusercontent.com/74512114/202331622-ee839ade-dbe8-4073-a0b1-e36e5fcabb8b.png)
- 하둡 에코 시스템 2.0에서는 맵-리듀스(Map-Reduce)를 버리고 YARN(Yet Another Resource Negotiator)을 채택하여 확장성과 데이터 처리 속도를 개선
