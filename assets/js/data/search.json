[ { "title": "[AI] Time Series 개요", "url": "/posts/Time-Series/", "categories": "AI, Time Series", "tags": "AI, Time Series", "date": "2023-01-05 21:27:02 +0900", "snippet": "Time Series Forecasting model Time SERIES Forecasting model의 분류Univariate : 하나의 특성을 사용Multivariate: 여러 개의 특성 사용TIme series Forecasting model 알고리즘 Autoregressive (AR) : 시계열의 이전 값과 이후 값 사이 어느 정도의 상관 관계(자기 상관)가 있을 때 사용 Autoregressive Integrated Moving Average (ARIMA) : 시계열 예측에 있어 가장 많이 사용되는 모델, 시계열 데이터 내 자체적으로 lagged (지연된) 데이터를 생성해 이를 예측한 오류를 기반으로 계산하는 방식 Seasonal Autoregressive Integrated Moving Average (SARIMA) : ARIMA에 계절성을 확장시킨 모델 Exponential Smoothing (ES) : 추세 또는 계절성을 사용한 univariate 데이터 예측 방법 XGBoost Prophet LSTM (Deep Learning)시계열 패턴추세(trend) 데이터가 장기적으로 증가하거나 감소할때, 추세(trend)가 존재 추세가 반드시 선형적일 필요는 없음계절성(seasonality) 해마다 어떤 특정한 때나 1주일마다 특정 요일에 나타나는 것 같은 패턴 계절성은 빈도의 형태로 나타나며, 그 빈도는 항상 일정주기성(cycle) 고정된 빈도가 아닌 형태로 증가나 감소하는 모습을 보일 때 경제 상황 때문에 발생, 흔히 “경기 순환(business cycle)”과 관련시계열 예제1) 미국 단독 주택 거래량: - 약 6~10년의 몇몇 강한 주기적 패턴이 보이지만 분명한 추세가 있지는 않음2) 미국 재무부 증권(treasury bill) 계약: 계절성은 없지만 하향하는 추세 있음3) 호주 분기별 전력 생산: 강한 계절성과 함께 강한 증가 추세4) 구글 주식 종가 기준 일별 변동 추세나 계절성, 주기적인 행동이 없음, 무작위적인 요동시계열 예측 딥러닝 모델에 영향을 주는 요소1) 데이터 수 : 늘릴수록 성능 향상2) history data : 이전 시점을 얼마만큼 사용하는지에 따라 성능 변화 없음 (어차피 자체적으로 현재 시점에서 가까운 데이터에 대한 가중치를 높게 설정하기 때문)3) future data : 현재 시점을 기준으로 더 멀수록 예측의 정확도가 낮아짐4) 이상치 필터링 : 이상치를 필터링할수록 성능이 눈에 띄게 성능이 향상됨 but 이상치를 필터링할 경우, 학습한 데이터 중 이상치가 없어 이상에 대한 예측이 불가함, 이상치가 축적되었을 때 학습시계열 예측 Process1) 데이터셋 탐색 - 기본 데이터 탐색적 분석2) 모델 학습을 위한 데이터 전처리 - 지도학습용 데이터로 변환(multi step) - 구축된 데이터를 학습용, 검증용, 시험용 데이터로 분리 - 데이터 스케일링3) 모델 학습 및 예측값 확인" }, { "title": "[AI] R-CNN/Fast R-CNN/Faster R-CNN 정리", "url": "/posts/R-CNN-Faster-R-CNN/", "categories": "AI, Vision", "tags": "AI, vision, object detection", "date": "2023-01-03 23:24:12 +0900", "snippet": " Object Detection 참고1-stage detector : 1-stage는 2-stage와 다르게 RoI영역을 먼저 추출하지 않고 전체 image에 대해서 convolution network로 classification, box regression(localization)을 수행2-stage detector : Selective search, Region proposal network와 같은 알고리즘을 및 네트워크를 통해 object가 있을만한 영역을 우선 뽑아낸다. 이 영역을 RoI(Region of Interest)라고 한다. 이런 영역들을 우선 뽑아내고 나면 각 영역들을 convolution network를 통해 classification, box regression(localization)을 수행한다. 대표적인 2-Stage Detector R-CNN, Fast R-CNN, Faster R-CNN R-CNNR-CNN Process R-CNN은 selective search를 통해 region proposal을 먼저 뽑아낸 후 CNN 모델에 들어간다. CNN모델에 들어가 feature vector를 뽑고 각각의 class마다 SVM로 classification을 수행한다.SVM : 서포트 벡터 머신(SVM: Support Vector Machine)은 분류 과제에 사용할 수 있는 강력한 머신러닝 지도학습 모델, 최적의 Decision Boundary(결정 경계)를 산출 localization error를 줄이기 위해 CNN feature를 이용하여 bounding box regression model을 수정한다. R-CNN 한계점1) RoI (Region of Interest, Object 가 있을 만한 영역) 마다 CNN연산을 함으로써 속도저하2) multi-stage pipelines으로써 모델을 한번에 학습시키지 못함Fast R-CNNFast R-CNN Process R-CNN에서와 마찬가지로 Selective Search를 통해 RoI를 찾는다. 전체 이미지를 CNN에 통과시켜 feature map을 추출한다. Selective Search로 찾았었던 RoI를 feature map크기에 맞춰서 projection시킨다. projection시킨 RoI에 대해 RoI Pooling을 진행하여 고정된 크기의 feature vector를 얻는다. feature vector는 FC layer를 통과한 뒤, 구 브랜치로 나뉘게 된다. 하나는 softmax를 통과하여 RoI에 대해 object classification을 한다. bounding box regression을 통해 selective search로 찾은 box의 위치를 조정한다.ROI Pooling feature map의 proposal region에서 미리 정해놓은 크기(FC layer의 인풋 사이즈)의 격자(grid)에 맞추어 bin마다 maxpooling 하여 고정된 크기의 vector를 만들어낸다.✔️ why? 사이즈가 제각각인 proposal region을 FC layer의 인풋으로 넣기위해 고정된 크기의 feature로 만들어 주기 위해.Faster R-CNNRPN(Region Proposal Network) 원본 이미지에서 region proposals를 추출하는 네트워크 region proposals에 대하여 class score를 매기고, bounding box coefficient를 출력(https://herbwood.tistory.com/10)" }, { "title": "[AI] 딥러닝 논문 일반적인 구현 패턴", "url": "/posts/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%85%BC%EB%AC%B8-%EA%B5%AC%ED%98%84%ED%8C%A8%ED%84%B4/", "categories": "AI, Deep Learning Theory", "tags": "AI, Deep Learning Theory", "date": "2022-09-30 21:27:50 +0900", "snippet": "딥러닝 논문 구현 방법 개요 일반적인 구현 패턴1) train.py : 모델 class를 인스턴스로 선언하고 For-loop을 돌면서 gradientdescent를 수행하면서 파라미터를 업데이트하는 로직 원하는 epoch만큼 파라미터를 업데이트 하는 실제 트레이닝 수행 - 추가적으로 파라미터 저장, 텐서보드 로그 저장등 추가 가능2) evaluate.py/test.py : Training된 파라미터를 불러와서 evaluation이나test/inference를 진행하는 로직 현재 파라미터에 기반한 학습에서 중간중간 파라미터의 성능을 평가 - 학습이 완전히 끝난경우 test/inference 진행 - 효율성을 위해 train.py 실행되는 도중 중간중간 evaluate.py/test.py 수행함으로 별도의 모듈로 작성함3) model.py : Keras Subclassing 형태의 모델 구조 class 정의 딥러닝 모델 구조를 class 형태로 정의 - train.py 에서 실제로 클래스 인스턴스를 선언할때 사용4) dataset.py : 데이터 전처리 및 batch 단위로 묶는 로직5) utils.py : 딥러닝 메인 로직 외에 유틸리티성 기능들을 모아 놓은 로직 ex) 이미지를 불러와 저장하거나, 학습 중간 결과를 GUI로 확인 하는 등의 기능 구현(딥러닝 메인 로직과는 별개)6) loss.py : 모델의 Loss Function을 정의 - yolo 처럼 loss Function이 복잡한 경우 별개의 모듈로 구현 - model.py / train.py에서 import하여 사용" }, { "title": "[AI] 딥러닝 논문 읽기 팁", "url": "/posts/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%85%BC%EB%AC%B8%EC%9D%BD%EA%B8%B0-%ED%8C%81/", "categories": "AI, Deep Learning Theory", "tags": "AI, Deep Learning Theory", "date": "2022-09-29 19:13:03 +0900", "snippet": "일반적인 딥러닝 논문의 구성1) Abstract : 논문의 전체적인 컨셉을 요약 설명2) Introduction : 논문의 아이디어 전개 방식 등에 대한 설명3) Method : 논문의 기법과 구현에 대한 아이디어 상세한 설명 - Model - Loss - Techniques4) Experiment : 논문의 기법의 성능에 대한 평가5) Conclusion : 논문의 내용을 정리 및 향후 연구방향 제시용어 state-of-the-art(SOTA) : 논문에서 제안한 기법이 동일한 종류의 기법중에서가장 뛰어난 성능을 가진다. end-to-end : 종단간 학습(input과 target 데이터만을 neural network에 맡기고 중간 개입이 없는 형태인neural network의 장점을 나타내는 용어) robust : (강건한), 딥러닝 논문에서 성능이 안정적이라는 의미 Tip읽는순서 추천1) Abstract, Conclusion을 먼저 읽고 논문의 아이디어 파악2) Introduction을 읽음3) Method 단락을 반복해 읽으며 논문의 아이디어를 상세히 파악" }, { "title": "[AI] Object Detection 문제영역과 metric 정리", "url": "/posts/Object_detection_%EB%AC%B8%EC%A0%9C%EC%98%81%EC%97%AD-%EC%A0%95%EB%A6%AC/", "categories": "AI, Vision", "tags": "AI, vision, object detection", "date": "2022-09-27 22:33:12 +0900", "snippet": "컴퓨터 비전의 대표적인 문제1) Image Classification 이미지를 알고리즘에 입력하여 그 이미지가 어떤 클래스 라벨에 속하는지 분류 하는것2) Semantic Image Segmentation 단순히 사진을 보고 분류하는 것에 그치지 않고 그 장면을 완벽하게 이해하는 수준의 문제 위의 사진 처럼 모든 픽셀을 해당하는 class로 분류 하는 것(이미지에 있는 모든 픽셀에 대한 예측을 하는 것이기 때문에 dense prediction 이라고도 불림)3) Object Detection 물체 검출은 이미지 내에서 알고리즘을 훈련시킬 때 사용된 라벨에 속하는 모든 물체를 검출하는 것 물체가 있는 영역의 위치 정보를 Bounding Box로 찾고 사물의 라벨을 분류Object Detection 문제 영역의 출력값 x_min, y_min, x_max, y_max, class, confidence ex) 사람의 경우 좌표가 (15,5), (240,297) 지점으로 바운딩 박스가 그려져 있다,class는 ‘person’이고 confidence는 0.92[참고 용어]Ground Truth 란? 문제 영역의 Ground Truth 데이터는 사람이 지정한 Bounding Box 와 Class LabelObject Detection의 성능 비교를 위한 정량적 지표 Intersection over Union(IoU) Metric 1개의 Bounding Box와 1개의 Bounding Box가 얼마나 일치하는 지를 0.0 ~ 1.0 사이로 표현 분모 부분엔 두 영역의 합집합, 분자 부분엔 두 영역의 교집합에 해당Metric 참고 Precision, Recall, F1 Precision : 정밀도(Precision)는 검색된 결과들 중 관련 있는 것으로 분류된 결과물의 비율(예측한 것 중에 맞춘 비율) → TP/(TP+FP) Recall : 재현율(Recall)은 관련 있는 것으로 분류된 항목들 중 실제 검색된 항목들의 비율(전체 갯수 대비 맞춘 갯수 비율) → TP/(TP+FN) ex) 이미지에 10개의 사과가 있고 모델이 6개의 사과를 검출, 이중 5개는 TP, 1개는 FP 일때,precision = 5/6 , Recall = 5/10 F1 : Precision과 Recall의 조화 평균, Precision과 Recall을 한번에 비교 → 2(prerec)/(pre+rec)결론 Precision과 Recall을 같이 비교하는 F1 스코어가 높아야 좋은 모델 위의 예시에서 precision만 봤을 때는 좋은 성능이지만, Recall은 그렇지 않음. 때문에 두 값을 종합해서알고리즘을 평가 하기 위한 AP(Aveage Precision) 필요Average Precision(AP) Positive 판단 기준 : 일정한 임계치의 IoU(Pascal VOC 데이터셋의 경우, 0.5)를 넘기면 맞춘 것으로 간주 Average Precision(AP) : Recall 별 Precision의 평균 AP는 Precision-Recall 그래프의 아래 면적 recall이 서서히 증가하다가 rank 10에서 5번째 True 일때 1.0recall에 따른 precision 그래프 B : Precision - Recall 그래프 C : 그래프 B에서 곡선의 아래 면적으로 해당 부분이 AP(Average Precision) mAP(mean Average Precision) 각각의 클래스에 대한 AP의 평균 Object Dectection의 평가 지표 " }, { "title": "[Python] 메모리 관리 개념 - 01", "url": "/posts/python-%EB%A9%94%EB%AA%A8%EB%A6%AC%EA%B4%80%EB%A6%AC01/", "categories": "Python", "tags": "Python", "date": "2022-09-25 19:30:40 +0900", "snippet": "메모리 할당 (Memory allocation) 정적 메모리 할당 프로그램 컴파일시 메모리가 할당 (C/C++) 고정 크기로만 정적 배열 선언 메모리는 컴파일할 때 할당되며, 스택은 정적 할당을 구현하는데 사용 이 경우 메모리 재사용이 불가능 동적 메모리 할당 프로그램 런타임시 메모리가 할당 (C/C++), new() 연산자를 사용하여 배열 선언 메모리는 런타임에 할당되며, 힙은 동적 할당을 구현 필요하지 않은 메모리를 비우고 재사용 가능 파이썬의 메모리 관리 파이썬의 모든것은 객체 이고, 동적 메모리 할당이 파이썬 메모리 관리의 기초 객체가 더 이상 필요하지 않으면 Python Memory Manager 가 자동으로 객체에서 메모리 회수 C/C++ 또는 자바의 경우 malloc과 같은 함수를 이용해서 동적 할당을 사용 Python은 동적 할당의 기능이 없음, 사용자가 직접 메모리 할당 범위를 조정하지 않음 Pythom Memory Manger : 포인터를 움직여 힙 영역의 메모리 할당 범위와 내부 버퍼를 조정,python memory manager 는 Python/C API를 통해 스토리지를 동적으로 관리 C언어에서 x=10과 같이 변수를 할당하면 메모리에 해당 값이 바로 저장되지만 파이썬은10이라는 int object를 만들어 놓고 변수 x가 그것을 가리키는 형태 y = x라고 하면 x에 의해서 이미 만들어진 10이라는 int object를 y가 가리킴(x 와 y는 같은 object) x = x+1은 11이라는 새로운 int object를 생성, x는 새롭게 만들어진 int object를 가리킴 z = 10 이라는 값을 생성하면 10 int object는 이미 생성되어 있으므로 가리키기만 한다." }, { "title": "[Data Engineering] Hadoop 생태계 정리", "url": "/posts/hadoop-echo-system/", "categories": "Data Engineering", "tags": "hadoop", "date": "2022-09-24 19:10:12 +0900", "snippet": "Hadoop Echo System 하둡에서 데이터를 분석 유지 저장 관리 할 때 필요한 모든 것들 작업 구분별 주요 기술 구분 주요 기술 데이터 수집 플럼(Flume), 스쿱(Sqoop) 데이터 저장,활용 Hbas 데이터 처리 하이브(Hive),피그(Pig),마후트(Mahout) 데이터 관리 우지(Oozie), H카탈로그(HCatalog), 주키퍼(Zookeeper) 작업 흐름도1) HDFS(하둡 저장 시스템)2) MapReduce(데이터를 key value로 변경)3) Hbase(변경된 데이터를 데이터베이스로 저장)4) Pig, Hive, Mahout, Oozie(데이터를 분석)하둡 사용자 인터페이스(Hue, Zeppelin) 하둡 휴(Hue, Hadoop User Experience) 하둡과 하둡 에코시스템의 지원을 위한 웹 인터페이스를 제공하는 오픈 소스 Hive 쿼리를 실행하는 인터페이스를 제공하고, 시각화를 위한 도구를 제공 job의 스케줄링을 위한 인터페이스와 job, HDFS, 등 하둡을 모니터링하기 위한 인터페이스도 제공 Zeppelin Zeppelin은 한국의 NFLab이라는 회사에서 개발하여 Apache top level 프로젝트로 최근 승인 오픈소스 솔루션으로, Notebook 이라고 하는 웹 기반 Workspace에 Spark, Tajo, Hive, ElasticSearch 등 다양한 솔루션의 API, Query 등을 실행하고 결과를 웹에 나타내는 솔루션 Pig 와 Hive Project Pig : [Yahoo] 많은 사람들이 사용할 수 있도록 MapReduce 프로그램을 만들어 주는 고수준 언어를 만들겠다는 목적으로 만들어짐 HIVE : [Facebook] SQL(유사) 구문에서 MapReduce를 자동생성하겠다는 목적으로 만들어짐YARN(Yet Another Resource Negotiator) YARN은 Hadoop v1에 있던 Job Tracker의 병목현상을 제거하기 위해 Hadoop v2에 도입 가장 효율적인 방법으로 계산 리소스를 할당하고 사용자 애플리케이션을 스케줄링하는 시스템 YARN은 빅데이터 처리에 사용되는 대규모 분산 운영체제 라고도 할 수 있다. 다양한 데이터 처리 엔진을 통해 HDFS (Hadoop 분산 파일 시스템)에 저장된 데이터를 실행하고 처리YARN 주요 컴포넌트 Resource Manager : 자원을 시스템의 응용프로그램(Application)에 할당이 가능하다. Nodes Manager : CPU, 메모리 같은 자원의 할당된 것을 일하고 Resource Manager에 보고한다. Application Manager : Resource Manager와 Nodes Manager 간의 인터페이스 역할을 한다." }, { "title": "[Data Engineering] Spark RDD 정리", "url": "/posts/spark-RDD-%EC%A0%95%EB%A6%AC/", "categories": "Data Engineering", "tags": "spark", "date": "2022-09-23 20:17:43 +0900", "snippet": "Spark RDD(Resillient Distributed Data)스파크의 데이터 구조 RDD (Resillient Distributed Data) Dataframe Dataset RDD : 스파크 도입 초창기부터 적용되었던 가장 첫번째 데이터구조 RDD Resillient(회복력 있는, 변하지 않는) : 메모리 내부에서 데이터가 손실 시 유실된 파티션을 재연산해 복구할 수 있음 Distributed(분산된) : 스파크 클러스터를 통하여, 메모리에 분산되어 저장됨 Data : 파일, 정보 등 DAG(Directed Acyclic Graph) 직관적 방향성의 비순환 그래프, 즉 반복이 일어나지 않는 그래프 DAG에 의하여 특정 RDD 관련 정보가 정보가 메모리에서 유실되었을 경우, 그래프를 복기하여 다시 계산하고, 자동으로 복구가능 스파크는 이러한 특성 때문에 Fault-tolerant(작업 중 장애나 고장이 발생하여도 예비 부품이나 절차가 즉시 그 역할을 대체 수행함으로써 서비스의 중단이 없게 하는 특성)를 보장한다. 노드간의 순환(cycle : 시작점과 끝점이 같은 형태)이 없으며, 각 노드 간에는 의존성이 있고 일정항 방향성을 가지고 있다. RDD는 회복력있는 분산형 데이터라는 뜻으로, RDD는 기본적으로 Read-Only로 수정 불가한 성격을 가지고 있다. 그렇기 때문에 이를 변형하기 위해서는 다른 RDD가 생성이 되고 이러한 과정은 DAG(Directed Acyclic Graph)로 히스토리가 기록이 된다. 이때 이런 히스토리를 Lineage(혈통)라고 부른다.-&gt; 특정 동작에 의해 생성되는 RDD Lineage는 DAG(Directed Acyclic Graph)의 형태를 가진다.RDD 동작 원리RDD의 Lineage RDD는 Transform을 수행하기 위해 DAG가 누적되지만 실제 물리적인 실행은 이루어지지 않는다. 클라이언트에서 실제 실행을 명령했을 때 위 그림상 Action() 분기를 만나 실제 수행하게 되는데 이때 RDD들의 DAG도 수행이 된다. 그렇기 때문에 중간 RDD과정에서의 데이터 유실이나 손상이 있더라도 원본데이터가 손상되지 않는 선에서 스파크는 데이터 복구가 용이하다." }, { "title": "[AI] 회귀분석 개념", "url": "/posts/%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80-%EA%B0%9C%EB%85%90/", "categories": "AI", "tags": "AI", "date": "2022-09-21 20:31:22 +0900", "snippet": "회귀분석 (Regression Analysis)둘 이상의 변수 간의 관계를 보여주는 통계적 방법. 일반적으로 그래프로 표현되며 종속 변수와 독립 변수 간의 관계를 테스트한다. 독립변수(independent variable) : 종속변수에 영향을 미치는 변수 (변수 변화 원인이 모형 밖에 있음) 종속변수(dependent variable) : 분석의 대상이 되는 변수 (변수 변화 원인이 모형 안에 있음) 회귀 분석의 시나리오 예시:1) 가상의 소매 기업이 다음 달(또는 종속 변수)의 판매 수치를 예측하고자 함.2) 날씨, 새 모델 출시, 경쟁업체가 수행하는 작업 또는 외부 포장 도로에서 진행 중인 유지 관리 작업(독립변수) 등을 고려3) 회귀 분석을 통해 측정 가능한 모든 변수를 정렬, 어떤 변수가 영향을 미칠 것인지 논리적으로 분석4) 분석을 통해 판매에 영향을 미치는 요인과 변수가 서로 상호 작용하는 방식 산출5) 기업의 의사결정에 반영→ 종속 변수 : 판매, 독립 변수: 날씨, 경쟁사 행동, 보도 유지 관리 및 새 모델 출시선형 회귀(Linear regression)머신러닝에서 가장 일반적인 회귀분석 유형이라고 할 수 있는 선형 회귀는 예측 변수와 종속 변수로 구성되며, 이 둘은 선형 방식으로 서로 연관지어져 있다. 선형 회귀는 위에서 설명한 대로 가장 적합한 선, 즉 최적적합선을 사용한다.변수들이 서로 선형적으로 연결되어 있는 경우 선형 회귀를 사용한다. 광고 지출 증가가 판매에 미치는 영향을 예측할 때 등이 예가 될 수 있다. 그러나 선형 회귀분석은 특이치에 영향을 받기 쉬우므로 빅데이터 집합을 분석하는 데 사용해서는 안 된다.머신러닝에서의 학습(Leaning)이란?트레이닝 데이터를 분석하고 데이터의 분포를 가장 잘 나타내는(오차가 최소인) 일차함수의 기울기(가중치) W, y절편 b(bias)를 찾는 과정→ y = Wx + b Loss/Cost Function (손실 함수) 손실함수의 목적 : 빨간선(평균값과 예측값의 차이)의 총합을 최소화 하여 최적의 결괏값을 도출 하는 것 손실 함수는 데이터를 토대로 산출한 모델의 예측 값과 실체 값과의 차이를 표현하는 지표로, 모델 성능의 ‘나쁨’을 나타낸다. 어떤 방식으로 표현하느냐에 따라 여러가지 손실 함수가 존재ex) 회귀 타입 : MAE,MSE,RMSE , 분류 타입 : Binary cross-entropy , Categorical cross-entropy#### MSE(Mean Square Error) Cost Function(손실함수 혹은 비용함수)에서, 영상처리에서는 화질 개선을 위해 원본 대비 화질을 측정하는 PSNR에서 주로 쓰인다 손실 함수에서의 오차(y -y^) 계산시 오차 부호의 혼재, 총합 0 등의 판단 에러를 방지하기 위해 값을 제곱한다." }, { "title": "[Data Engineering] Spark 개요 및 구조", "url": "/posts/spark-%EA%B8%B0%EB%B3%B8%EA%B0%9C%EC%9A%94-%EA%B5%AC%EC%A1%B0/", "categories": "Data Engineering", "tags": "spark", "date": "2022-09-20 21:00:23 +0900", "snippet": "Spark란? Spark은 “General Purpose High Performance Distributed Platform (범용 목적의 분산 고성능 클러스터링)”이다. 빅데이터 처리를 위한 오픈소스 분산 처리 플랫폼 Scala로 개발되었으며 Python/Java/R을 추가로 지원한다spark 등장 배경빅데이터의 개념이 등장하였을 당시,”빅데이터 처리 = 하둡(Hadoop)”이라고 할 정도로,하둡 에코시스템이 시장을 지배하였다.하둡은 HDFS(Hadoop Distributed File System)라고 불리는, 분산형 파일 시스템을 기반으로 만들어졌으며,HDFS와 ‘맵리듀스’라고 불리는 대형 데이터셋 병렬 처리 방식에 의해 동작한다.1) 하둡의 HDFS는 DISK I/O를 기반으로 동작하는데, 실시간성 데이터에 대한 니즈(NEEDS)가 급격하게 증가하면서,하둡으로 처리하기에는 속도 측면에서 부적합한 시나리오들이 등장하였다.2) 컴퓨터 H/W들의 가격이 빠른 속도로 다운되면서, 기존에 고가로 취급되던 메모리를 고용량으로 사용할 수 있게 되었다. 위의 문제를 개선하기 위해 등장 한 것이 ‘아파치 스파크’ 아파치 스파크는 인메모리상에서 동작 하므로, 반복적인 처리가 필요한 작업에서 속도가 하둡보다 최소 1000배 이상 빠르며 이를 통해 데이터 실시간 스트리밍 처리라는 니즈를 충족 최근엔 하둡 + 스파크 연계방식으로 많이 사용하며 하둡의 YARN 위에 스파크를 얹고, 실시간성이 필요한 데이터는 스파크로 처리하는 방식으로,대부분의 기업들과 연구단체에서 이와 같은 아키텍처를 구성하여 동작 중에 있다. 스파크의 구조스파크의 다양한 컴포넌트와 라이브러리 Scala, JAVA, Pyhon 등의 다양한 언어 기반의 고수준 API를 사용 가능하다. SQL의 기능을 담당하는 Spark SQL 여러 머신러닝 기법을 지원하는 MLlib, MLlib는 최근 크게 각광받고 있으며, 금융권 등 국내의 데이터 실시간 분석에서 스파크 비율이 압도적으로 높은추세이다. 실시간 데이터 처리를 지원하는 Spark Streaming , spark streaming 은 Kafka, Hadoop과 연계 가능한 스파크의 확장성 덕분에, 위와 같은 구조로 대부분의 기업에서 활용되고 있다.카프카, 플럼, 키네시스, TCP 소켓 등 다양한 경로를 통해서 데이터를 입력 받고, map, reduce, window 등의 연산을 통해 데이터를 분석하여 최종적으로 파일시스템, 데이터베이스 등에 적재한다.Spark Application Spark Driver 한 개의 노드에서 실행되며, 스파크 전체의 main() 함수를 실행 어플리케이션 내 정보의 유지 관리, 익스큐터의 실행 및 실행 분석, 배포 등의 역할을 수행 사용자가 구성한 사용자 프로그램(Job)을 task 단위로 변환하여, Executor로 전달 Executor 다수의 worker 노드에서 실행되는 프로세스 Spark Driver가 할당한 작업(task)을 수행하여 결과를 반환 하거나 블록매니저를 통해 cache하는 RDD를 저장한다 Cluster Manager 클러스터 매니저는 스파크와 붙이거나 뗄 수 있는, Pluggable한 컴포넌트로, 스파크 어플리케이션의 리소스를 효율적으로 분배하는 역할 스파크는 익스큐터를에 태스크를 할당하고 관리하기 위하여 클러스터 매니저에 의존 이 때, 스파크는 클러스터 매니저의 상세 동작을 알지 못한다.(Black-box)단지 클러스터 매니저와의 통신을 통하여, 할당 가능한 Executor를 전달받는다. 스파크 3.0 기준으로, 사용 가능한 클러스터 매니저에는 Spark StandAlone, (Hadoop)Yarn, Mesos, Kubernetes 등이 있다. Spark StandAlone 클러스터가 아닌 단일 컴퓨터에서 스파크 전체를 동작시키는 방식 이 때 Spark Driver와 Executor는 각각 thread로 동작 Worker 노드에 여러개의 Executor를 실행시킬 수 있는 Yarn, Mesos, K8s와 달리,StandAlnoe 모드의 경우 Executor는 Worker 노드 하나당 한개 씩 동작Spark Application 실행 과정 Spark application :클러스터에서 독립된 프로세스들의 묶음으로 동작하며, 메인 프로그램(driver Program)의 SparkContext object에 의해서 조정된다. Driver Program(프로세스)가 main을 실행시키며 SparkContext 생성한다. SparkContext가 Cluster Manager에 연결된다. 연결되면, 클러스터 내의 Executor를 할당받는다. SparkContext가 application code(SparkContext에 전달된 Jar 또는 Python file)를 executor에 보낸다. SparkContext가 실행할 task를 executor에 보낸다.요약 : 사용자 프로그램을 수행하기 위하여, Spark Driver 내의 Spark Context가 Job을 task 단위로 쪼갠다. Cluste Manager로부터 할당받은 Executor로 task를 넘긴다." }, { "title": "[AI] CNN 기본 이론", "url": "/posts/CNN-%EA%B0%9C%EB%85%90-%EC%A0%95%EB%A6%AC/", "categories": "AI, Vision", "tags": "AI, CNN", "date": "2022-09-20 19:12:40 +0900", "snippet": "CNN(Convolutional Neural Network) - 합성곱 신경망 CNN 에서 특별히 합성곱이 일어나는 층을 합성곱층, 풀링이 일어나는 층을 풀링층이라고 부름 합성곱층과 풀링층에서 만들어진 결과를 특성 맵(feature map)이라고 부른다. 입력이 합성곱층을 통과할 때 합성곱과 활성화 함수가 적용되어 특성 맵이 만들어짐,그 다음 특성 맵이 풀링층을 통과하여 또 다른 특성 맵이 만들어짐 풀링이란? 특성맵을 스캔하여 최댓값을 고르거나 평균값을 계산하는 것 CNN의 구조합성곱 층(Convolution Layer) 각각 합성곱 층의 뉴런은 입력 이미지의 모든 필에 연결되는 것이 아니라 합성곱 층 뉴런의 수용장에 있는 픽셀만 연결됨 두 번째 합성곱 층은 첫 번째 합성곱 층의 작은 사각 영역 안에 위치한 뉴런에만 연결스트라이드(stride) 스트라이드가 2 이고, 수용장의 크기가 33으로 할 때 출력의 크기 33 만약 스트라이드가 1이라면 출력은 5*5 -&gt; 스트라이드가 커지면 출력의 크기는 작아짐패딩 feature map이 작아지는 문제를 해결하기 위한 기법 패딩을 1로 설정 한 후 값을 0으로 넣는다여러 가지 특성 맵 합성곱 층은 여러 가지 커널을 가지고 커널마다 하나의 특성 맵을 출력 실제로는 2D가 아니라 3D로 표현 각 특성 맵의 픽셀은 하나의 뉴런에 해당하고, 하나의 특성 맵 안에서는 모든 뉴런이 같은 파라미터(동일한 가중치와 편향, 즉 커널)를 공유하지만, 다른 특성 맵과는 다른 파라미터를 사용하여 파라미터 수를 급격히감소 시킴→ 하나의 합성곱 층이 입력에 여러 필터를 동시에 적용하여 입력에 있는 여러 특성을 감지풀링 층(Pooling Layer) 과도한 계산량, 메모리 사용량, 파라미터 수를 줄이고 over fitting 위험을 줄여주는 축소본 생성 풀링 뉴런은 가중치 없이 최대나 평균만 계산 풀링 종류 average pooling : 평균을 구하므로 max pooling 보다 정보 손실이 적음 max pooling : 의미 없는 것들을 제거하고 큰 특징만 유지, 조금더 명확, 일반적으로성능이 더 좋아서 max pooling 이용 CNN 기본 이론 요약 입력된 이미지를 Convolution Layer의 뉴런이 Kernel 이라는 특징을 통과해 특정한특징만 가지고 있는 Feature Map 가짐, 이러한 Feature Map을 통해서 이미지 인식 Feature Map 작아지는 문제점이 있어 Padding 기법 활용, 계산 복잡도를 낮춰주기 위해 stride 설정 Convolution Layer만 있다면, 과대 적합이 심해질 수 있으므로, Pooling Layer 추가 " }, { "title": "[Data Engineering] Hadoop 개념 정리", "url": "/posts/hadoop-%EA%B0%9C%EB%85%90%EC%A0%95%EB%A6%AC/", "categories": "Data Engineering", "tags": "hadoop", "date": "2022-09-20 17:15:16 +0900", "snippet": "Hadoop 기본 개념 Hadoop (High-Availability Distributed Object-Oriented Platform) 자바 소프트웨어 프레임워크로 빅데이터 분산 처리 프레임워크 하나의 컴퓨터가 처리할 일을 여러 대의 컴퓨터가 병렬적으로 처리함으로써 처리속도를 현저히 단축시켜주고 데이터 파일도 분산 저장할 수 있도록 함 하둡의 장.단점장점 오픈소스로서 비용 부담이 적다. 시스템을 중단하지 않고 서버의 증설이 가능하다. 저렴한 구축비용과 데이터 처리가 빠르다. 배치성 프로세스에 최적화 되어있다.단점 HDFS에 저장된 데이터를 변경할 수 없다. 실시간 데이터에 대해서는 하둡만으로는 부적합하다. 기술지원이 좋지 않다. 설정할 요소가 많고 복잡하다.HDFS(Hadoop Distributed FileSystem) 하둡 분산형 파일시스템(HDFS)는 하둡 네트워크에 연결된 기기에 데이터를 저장하는 분산형 파일시스템으로 실시간 처리보다는 배치처리를 목적으로 설계되었다. 따라서 작업량이 작거나 빠른 데이터 응답이 필요한 작업에서는 적합하지 않다. HDFS의 특징 데이터를 블록 단위로 나누어 저장한다. 따라서 큰 데이터를 나누어 저장하므로 단일 디스크 보다 큰 파일도 저장이 가능ex) 블록단위가 256MB라면 1G파일은 4개의 블록으로 나누어 저장된다. 블록에 문제가 생겨 데이터가 손실되는 경우를 막기 위해 HDFS는 각 블록을 복제하여 중복 저장함 HDFS는 읽기 중심을 목적으로 만들어 졌기 때문에 파일의 수정은 지원하지 않는다. (읽는 속도를 높인다.) 맵리듀스(아래에서 나옴)는 HDFS의 데이터의 지역성을 이용해서 처리 속도를 증가시킨다.(데이터 처리시 데이터 위치에서 알고리즘을 처리하여 데이터 이동 비용 감소시킴) HDFS 구조(Architecture) HDFS는 기본적으로 마스터 슬레이브 구조 마스터/슬레이브(Master/Slave)마스터/슬레이브(Master/slave)는 장치나 프로세스(마스터)가 하나 이상의 다른 장치나 프로세스(슬레이브)를 통제하고 통신 허브 역할을 하는 비대칭 통신 및 제어 모델 MapReduce는 일을 어떻게 나눠서 수행하는지를 Master에서 관리 HDFS는 저장 시 어떻게 분산 저장할 지를 Master에서 관리 네임노드는 메타데이터를 가지고 있고, 데이터는 블록 단위로 나누어 데이터노드에 저장 데이터를 읽고 쓰려면 사용자는 메타데이터를 가지고 있는 네임노드를 이용네임노드와 데이터노드의 역할 네임노드 메타데이터를 관리 데이터 노드들을 모니터링, 데이터노드들은 3초마다 한 번씩 네임노드에게 하트비트 메시지를 전송함으로써 데이터 노드들의 실행 상태와 용량을 모니터링 블록들을 관리, 만약 특정 데이터 노드에 장애가 발생하면 해당 데이터 노드의 블록을 새로운 데이터 노드로 복제. 또한 용량이 부족한 데이터 노드가 있다면 용량에 여유가 있는 데이터 노드로 블록을 이동시킵니다. 클라이언트의 요청을 처리 메타데이터 메타데이터는 파일이름, 파일크기, 파일생성시간, 파일접근권한, 파일 소유자 및 그룹 소유자, 파일이 위치한 블록의 정보 등으로 구성 데이터 노드 데이타노드는 파일을 저장하는 역할을 하며, 이떄 파일은 블록단위로 저장 주기적으로 네임노드에 하트비트와 블록리포트를 전달 하트비트 : 데이터노드의 동작여부를 판단하는데 이용, 네임노드에서는 하트비트가 전달되지 않는데이터노드는 동작하지 않는 것으로 판단하여 더이상 데이터를 저장하지 않도록 설정한다.블록리포트 : 블록의 변경사항을 체크하고, 네임노드의 메타데이터를 갱신한다. 블록파일은 사용자가 설정한 위치(dfs.data.dir)에 저장 데이터 노드의 경우 클라이언트가 HDFS에 저장하는 파일의 블록을 데이터 노드 로컬 디스크에 유지하고 분산 처리 작업 발생시 작업을 처리 데이터 노드의 상태를 나타내는 정보로 활성상태와 운영상태 확인하둡의 동작 흐름 데이터가 들어오면 데이터를 분해,분리 하여 저장 데이터를 나눈 후 어느 데이터 노드에 저장 되어있는 기록해 놓는(메타데이터) 필요-&gt; 네임노드에서 분산을 하고 저장위치를 분배, 그 후 여러개 중에 지정된 데이터 노드에 저장HDFS 파일 사용 HDFS 파일 읽는 순서 open() 명령어를 통해 DistributedFileSystem에 있는 FileSystem의 파일을 연다 PRC()를 NameNode를 호출하여 저장되어있는 블록이 저장된 DataNode의 주소를 받는다. DistributedFileSystem은 client가 데이터를 검색할 수 있도록 검색을 지원하는 입력 스트림인 FSDataInputStream를 client에게 준다. 그러면 그것을 통해 찾고자 하는 datanode와 DFSInputStream이 맵핑된다. 그리고 검색후 read() 명령어를 통해 호출을한다. datanode 주소가 저장된 DFSInputStream은 datanode와 연결되고, 데이터는 datanode에서 클라이언트로 가게된다. 이러한 형식으로 반복 read()가 호출하여 파일을 읽는다. 블록 끝에 도달하면 DFSInputStream은 데이터 노드에 대한 열결을 닫고, 다음 블록에 가장 접합한 데이터 노드를 찾는다. 읽기가 마치면 FSDataInputStram에서 close()를 호출한다. HDFS Federation HDFS Federation은 디렉토리 단위로 네임노드를 등록하여 사용하는 것으로, 파일이 많아짐에 따른 메모리 관리 문제를 해결하기 위해 하둡 v2 부터 지원 ex) /user, /hadoop, /tmp 각각의 디렉토리 단위로 총 3개의 네임노드를 실행, 독립적으로 관리하여 다른 네임 노드에 영향을 주지 않는다. HDFS High Availability(고가용성) 네임노드에 문제가 발생하면 모든 작업이 중지되고, 파일을 읽거나 쓸수 없게 된다. 하둡 v2에서 이 문제를 해결하기 위해서 HDFS High Availability을 제공 이중화된 두대의 서버인 액티브(active) 네임노드와 스탠바이(standby) 네임노드를 이용하여 지원엑티브 네임노드 : 네임노드의 역활을 수행스탠바이 네임노드 : 액티브 네임노드와 동일한 메타데이터 정보를 유지하다가, 액티브 네임노드에 문제가 발생하면 스탠바이 네임노드가 액티브 네임노드로 동작 액티브 네임노드에 문제가 발생하는 것을 자동으로 확인하는 것이 어렵기 때문에보통 주키퍼를 이용하여 장애 발생시 자동으로 스탠바이 네임노드로 변경될 수 있도록 한다. 스탠바이 네임노드는 세컨더리 네임노드의 역할을 동일하게 수행하기 때문에, HDFS를 고가용성 모드로 설정하였을 때는 세컨더리 네임노드를 실행하지 않아도 된다. 고가용성 모드에서 세컨더리 네임노드를 실행하면 오류가 발생한다.Zookeeper : 분산 시스템 간의 정보 공유 및 상태 체크, 동기화를 처리하는 프레임워크로 이러한 시스템을 코디네이션 서비스 시스템이라고 한다. HDFS safemode safemode는 읽기 전용 상태로 데이터 노드 수정이 불가능하며, 데이터의 추가, 수정, 복제가 일어나지 않는다. 보통 safemode는 노드에 문제가 생겼거나 서버 운영 정비를 위해 설정을 한다. # 세이프 모드 상태 확인$ hdfs dfsadmin -safemode getSafe mode is OFF# 세이프 모드 진입$ hdfs dfsadmin -safemode enterSafe mode is ON# 세이프 모드 해제$ hdfs dfsadmin -safemode leaveSafe mode is OFF맵리듀스(Map Reduce) Goggle MapReduce를 참고해서 Hadoop MapReduce 프레임워크가 만들어짐 하둡 분산 파일 시스템(HDFS)은 대용량 파일을 지리적으로 분산되어 있는 수많은 서버에 저장하는 솔루션이며,맵-리듀스는 분산되어 저장된 대용량 데이터를 병렬로 처리하는 솔루션 특정 데이터 노드만 분석하고 결과만 받는 것이 맵-리듀스 -&gt; 통합분석이 아닌, 개별분석 후 결과를 취합Map 단계 Map은 분산되어있는 컴퓨터에서 처리 Map단계에서는 흩어져 있는 데이터를 key, value로 데이터를 묶어준다. key는 몇 번째 데이터인지, value는 값을 추출한 정보를 가진다. ‘빅데이터’가 key라면 value는 빅데이터라는 키가 몇번 나오는지의 숫자. key와 value를 구한 후에 통합하기 위해 통합하는 곳(Reduce)으로 보내준다.-&gt; Map은 흩어져 있는 데이터를 Key, Value의 형태의 연관성 있는 데이터 분류로 묶는 작업Reduce 단계 최종적인 통합관리를 위해 Reduce를 해주는 것이다. ex) [A] key: 빅데이터, value: 5 / [B]: key: 빅데이터, value: 10 일때 Reduce는 빅데이터가 총 15번 나왔다고 통합 Reduce단계는 Map단계의 key를 중심으로 필터링 및 정렬, 하둡에서는 이 Map과 Reduce를 함수를 통해서 구현하고 맵리듀스 잡을 통해 제어-&gt; Reduce는 Filtering과 Sorting을 거쳐 데이터를 추출, Map 작업 중 중복데이터를 제거하고 원하는 데이터를 추출하는 작업버전에 따른 MapReduce 차이 하둡 에코 시스템 2.0에서는 맵-리듀스(Map-Reduce)를 버리고 YARN(Yet Another Resource Negotiator)을 채택하여 확장성과 데이터 처리 속도를 개선" }, { "title": "Dynamic Programming", "url": "/posts/Dynamic-Programming/", "categories": "Algorithm", "tags": "Algorithm, python, DynamicProgramming", "date": "2022-09-18 21:19:00 +0900", "snippet": "Dynamic Programming 프로그래밍에서 다이나믹이란? ‘프로그램이 실행되는 도중에 ‘ 라는 의미 다이나믹 프로그래밍 사용 조건1) 큰 문제를 작은 문제로 나눌 수 있다.2) 작은 문제에서 구한 정답은 그것을 포함하는 큰 문제에서도 동일하다. Memoization(메모이제이션) 기법이란? 다이나믹 프로그래밍을 구현하는 방법 중 하나로, 구한 결과를 메모리공간에 저장하고 같은 식을 호출하면 저장한 값을 가져오는 방식 값을 저장하는 방법으로 캐싱(caching)이라고도 한다 # Memoization을 활용한 피보나치 수열 구현# Memoization -&gt; 탑다운 방식# 한 번 계산된 결과를 메모이제이션 하기 위한 리스트 초기화d = [0] * 100# 피보나치 함수(Fibonacci Function)를 재귀함수로 구현(탑다운 다이나믹)def fibo(x): # 종료 조건(1 혹은 2일 때 1을 반환) if x == 1 or x == 2: return 1 # 이미 계산한적 있는 문제라면 그대로 반환 if d[x] != 0: return d[x] # 아직 계산하지 않은 문제라면 점화식에 따라 피보나치 반환 d[x] = fibo(x-1) + fibo(x-2) return d[x]print(fibo(99))# 피보나치수열 보텀업 방식# 앞서 계산된 결과를 저장하기 위한 DP 테이블 초기화d = [0] * 100# 첫 번째 피보나치 수와 두 번째 피보나치 저장d[1] = 1d[2] = 1n = 99# 피보나치 반복문으로 구현(보텀업 다이나믹 프로그래밍)for i in range(3, n+1): d[i] = d[i-1] + d[i-2]print(d[n]) 보텀업 방식에서 사용되는 결과 저장용 리스트는 ‘DP 테이블’ 이라고 부르며메모이제이션은 탑다운 방식에 국한되어 사용되는 표현이다." }, { "title": "Binary Search", "url": "/posts/binary-search/", "categories": "Algorithm", "tags": "Algorithm, python, BinarySearch", "date": "2022-09-17 00:00:00 +0900", "snippet": "BinarySearch# 이진 탐색 재귀 구현'''- 인덱스 시작점, 끝점 확인- 양끝의 인덱스 나누어 가운데 인덱스 저장- 찾는 수가 가운데 인덱스 값보다 크면 오른쪽, 작으면 왼쪽 탐색- 위 단계 반복- array 전체 배열, target 찾는 값, start 시작 인덱스,end 끝 인덱스'''def binary(array, target, start, end): if start &gt; end: return None mid = (start + end)//2 print(f'mid : {mid}') if array[mid] == target: return mid elif target &gt; array[mid]: return binary(array, target, mid+1, end) # binary(array, target, mid+1, end) elif target &lt; array[mid]: return binary(array, target, start, mid-1) else: print('none') pass# 전체 원소 갯수, 타겟 넘버n, k = map(int, input().split())array00 = list(map(int, input().split()))result = binary(array00, k, 0, n-1)if array00[result] == k: print(result+1)else: print('원소가 존재 하지 않음')####" }, { "title": "Design Patterns 개요", "url": "/posts/Design-patterns-%EA%B0%9C%EC%9A%94/", "categories": "CS, Design Patterns", "tags": "CS, Python, Design Patterns", "date": "2022-08-02 19:20:00 +0900", "snippet": "SOLID 원칙객체지향 설계 원칙1) Single Responsibility Principle 하나의 클래스는 하나의 역할만을 수행2) Open - close Principle 확장(상속)에는 열려있고, 수정에는 닫혀 있어야 함3) Liskov Substitution Principle 자식이 부모의 자리에 항상 교체될 수 있어야 한다 부모의 property / method 모두를 자식이 가지고 있어야 함4) Interface Segregation Principle 인터페이스가 잘 분리되어 클래스가 꼭 필요한 인터페이스만 구현이 되어있음5) Dependency Inversion Property 상위 모듈이 하위 모둘에 의존하면 안됨 메타 클래스 / 추상화 클래스에 의존(필요하면), 추상화 자체는 세부 사항에 의존하면 안됨Design Pattern잘 설계된 구조의 형식적 정의. 다양한 디자인 패턴으로 서로 다른 문제를 해결 가능디자인 패턴이 필요한 이유 중복되는 코드 개발을 하고 싶지 않을 때 “바퀴를 다시 발명하지 마라” 업무의 분리를 위해, 개념을 압축해 효율적인 커뮤니케이션 가능 유지보수 용이 / 객체지향 기술 향상 -&gt; OOP 기술의 문제점에 대한 해결책 제시디자인 패턴의 구조 맥락(context) :문제가 발생하는 여러 상황을 기술한다. 즉, 패턴이 적용될 수 있는 상황을 나타낸다. 경우에 따라서는 패턴이 유용하지 못한 상황을 나타내기도 한다. 문제(problem) :패턴이 적용되어 해결될 필요가 있는 여러 디자인 이슈들을 기술한다. 이때, 여러 제약 사항과 영향력도 문제 해결을 위해 고려해야 한다. 해결(solution) :문제를 해결하도록 설계를 구성하는 요소들과 그 요소들 사이의 관계, 책임, 협력 관계를 기술한다.해결은 반드시 구체적인 구현 방법이나 언어에 의존적이지 않으며 다양한 상황에 적용할 수 있는 일종의 템플릿이다.파이썬 OOP 개념 및 디자인패턴 자료 참고주요 GOF 디자인 패턴1) Adapter Pattern용도 어떤 클래스를 바로 사용할 수 없을때. 다른곳에서 개발한 클래스이고, 이를 수절할 수 없을 떄, 중간에 변환할 역할을 해주는 클래스가 필요한데 이것이 바로 어댑터사용방법 상속 위임 : 어떤 메소드의 실제 처리를 다른 인스턴스의 메소드에게 맡기는 방법Class Diagram2) Prototype Pattern용도 미리 만들어진 객체를 복사해서 객체를 생성하는 방식 객체를 많이 만들어야 할 경우, 객체 생성에 드는 코딩 분량을 현저히 줄일 수 있다 클래스로부터 객체를 생성하기 어려운 경우(그래픽 에디터에서 사용자의 마우스 클릭으로 생성되는 객체들)사용 방법 모형(Prototype) 인스턴스를 등록해 놓고, 등록된 인스턴스를 복사(clone())해서 인스턴스를 생성함3) Singleton Pattern용도 시스템 내부에 1개의 인스턴스만 생성하고 싶은 경우 컴퓨터 자체를 표현한 클래스, 현재 시스템 설정을 표현한 클래스사용방법 생성자를 private으로 선언하고, 해당하는 생성자를 클래스 내부에서만 호출함4) Composite Pattern용도 틀과 내용물을 같은 것으로 취급하고 싶을 때(디렉토리 내부에는 디렉토리와 파일이 있지만, 둘 모두 디렉토리 내부에 있는 Element로 표현하고 싶을 때)사용 방법 Composite 클래스가 Component를 포함하도록 함5) Decorator Pattern용도 데코레이팅한 결과물을 다시 내용물로 보고 그것을 다시 데코레이팅하기 위함(지속적으로 장식을 추가할 때, 문자열 주위에 여러 유형의 border 장식을 추가할 때)사용 방법 데코레이터(decorator) 패턴은 @ 표기를 사용해 함수 또는 메서드의 변환을 지정해주는 도구이다. 데커레이터 패턴은 함수의 객체와 함수를 변경하는 다른 객체의 래핑 (wrapping) 을 혀용한다. 즉 클래스 내의 메서드를 재정의 하지 않고도 자동으로 다른 함수와 래핑 시켜준다.✔ Decorator가 Component를 포함하고 있음class C(object): @my_decorator def method(self): #메서드...'''이는 아래와 같은 코드이다.'''class C(object: def method(self): #메서드... method = my_decorator(method)# ================ Decorator 예제 ====================import randomimport timedef benchmark(func): def wrapper(*args, **kwargs): # *args(튜플형태 가변인자) , **kwargs(딕셔너리형태 가변인자) t = time.perf_counter() # 코드 수행시간 res = func(*args, **kwargs) # 들어오는 매개변수는 가변길이의 랜덤 리스트 print(f'{func.__name__} {time.perf_counter()-t}') return res return wrapper@benchmark## random_tree = benchmark(random_tree)def random_tree(n): temp = [n for n in range(n)] for i in range(n+1): temp[random.choice(temp)] = random.choice(temp) # 랜덤 리스트 생성 #temp = n return temprandom_tree(1000)# -&gt; random_tree 0.0005249# @classmethod , @staticmethod'''이들은 각각 메서드를 클래스 메서드와 정적 메서드로 변환한다. @classmethod는 첫 번째 인수로 클래스(cls)를 사용하고,@staticmethod는 첫 번째 인수에 self 혹은 cls가 없다. 클래스 내 변수에 접근하려면 @classmethod의 첫 번째 인수를 사용할 수 있다.'''class A(object):_hello = True def foo(self, x): print(f'{self} // {x}') @classmethod def class_foo(cls,x): # 클래스 내 변수에 접근하려면 @classmethod의 첫 번째 인수로 접근 print(f'class_foo({cls} , {x}) 실행 : {cls._hello}') @staticmethod def static_foo(x): print(f'static_foo({x})')a = A()a.foo(1)a.class_foo(2)A.class_foo(2)a.static_foo(3)A.static_foo(3)# foo(&lt;__main__.A object at 0x03CDA400&gt;, 1) 실행# class_foo(&lt;class '__main__.A'&gt;, 2) 실행: True# class_foo(&lt;class '__main__.A'&gt;, 2) 실행: True# static_foo(3) 실행# static_foo(3) 실행6) Facade Pattern용도 대규모 프로그램에는 서로 관련있는 클래스들이 많음 -&gt; 복잡하게 얽혀있는 클래스들을 정리해서 높은 레벨의 인터페이스(API)를 제공(간단하게 접근 가능) 여러 클래스들을 직접 제어하지 않고 ‘창구(facade)’에 요구함 결과적으로 구현시에 간단한 인터페이스를 사용할 수 있게함7) Proxy Pattern용도 proxy(대리인) -&gt; 시간이 많이 걸리는 작업은 대리인이 수행 시간이 많이 걸리는 작업을 할 때, 대리인이 할 수 있는 일은 대리인이 하고 할 수 없는 일(Heavy job)은 본래의 클래스에게 넘겨줌 ex) 시스템 초기화는 필요하지 않은 기능까지 초기화하려고 하면 많은 시간이 필요한데, 그 기능을 Proxy에 위임함프린트 프로그램에서 실제 프린터를 실행하는 과정에 시간이 오래 걸리기 때문에 그 과정에 있는 일들을 Proxy에 위임함 사용 방법 proxy 클래스에 우선 일을 위임하고, 그 뒤에 RealSubject가 해야할 일은 넘겨주는 방법으로 사용8) Observer Pattern용도 특정 값을 유지하는 핵심 객체를 갖고, 직렬화된 객체의 복사본을 생성하는 일부 옵저버(관찰자)가 있는 경우 유용하다.즉, 객체의 일대다(one-to-many) 의존 관계에서 한 객체의 상태가 변경되면, 그 객체에 종속된 모든 객체에 그 내용을 통지하여 자동으로 상태를 갱신하는 방식이다.(마치 provider 또는 subscriber) 옵저버 패턴은 @property 데커레이터를 사용해 구현할 수 있다.예를 들어 속성 (property)을 읽기 전용으로 설정하는 것과 같은 속성 접근 제어를 할 수 있다. 속성은 접근자 (accessor), getter/setter 메서드 대신 사용된다. 관찰 대상의 상태가 변화했을 때 관찰자에게 통지하는 패턴 상태 변화에 따른 처리를 기술할 때 효과적으로 활용 (MVC패턴에서 model과 view의 분리 등) 이벤트 핸들러 : Observer , 이벤트 : Subject / observer 객체들은 subject에 의존성을 갖는다. subject 객체를 관찰하여 변경을 감지하고자 하는 객체를 observer로 등록하고 변경이 되었을 때, 이를 탐지ex) a라는 유튜브 채널(subject)을 A,B,C 라는 사람이 구독을 하게 되면(observer) 해당 채널에 새로운 영상이나 글이 올라올 경우(객체의 상태 변경), 해당 유튜브를 구독한 A,B,C는 알림을 받게 된다. -&gt; 1(subject) : N(observer) 구조사용 방법 Observer 클래스에 상태 변화를 알려주고, Observer는 다시 그 변화에 맞는 결과를 나타냄# 옵저버 패턴 구현 예제class Subscriber(object): def __init__(self, name): self.name = name def update(self, message): print(f'{self.name} , {message}')class Publisher(object): def __init__(self): self.subscribers = set() def register(self, who): self.subscribers.add(who) def unregister(self, who): self.subscribers.discard(who) def dispatch(self, message): for subsciber in self.subscribers: subsciber.update(message)pub = Publisher()beom = Subscriber('Beom')ben = Subscriber('Ben')seok = Subscriber('Seok')pub.register(beom)pub.register(ben)pub.register(seok)pub.dispatch(\"lunch\")pub.unregister(ben)pub.dispatch(\"dinner\")" }, { "title": "Object Detection 개요", "url": "/posts/Detection/", "categories": "AI, Vision", "tags": "AI, object detection", "date": "2022-08-01 19:14:00 +0900", "snippet": "객체 탐지 (Object Detection) 한 이미지에서 객체와 그 경계 상자(bounding box)를 탐지 객체 탐지 알고리즘은 일반적으로 이미지를 입력으로 받고, 경계 상자와 객체 클래스 리스트를 출력 경계 상자에 대해 그에 대응하는 예측 클래스와 클래스의 신뢰도(confidence)를 출력Applications 자율 주행 자동차에서 다른 자동차와 보행자를 찾을 때 의료 분야에서 방사선 사진을 사용해 종양이나 위험한 조직을 찾을 때 제조업에서 조립 로봇이 제품을 조립하거나 수리할 때 보안 산업에서 위협을 탐지하거나 사람 수를 셀 때Bounding Box 이미지에서 하나의 객체 전체를 포함하는 가장 작은 직사각형 IOU(Intersection Over Union) 실측값(Ground Truth)과 모델이 예측한 값이 얼마나 겹치는지를 나타내는 지표 IOU가 높을수록 잘 예측한 모델 (1에 가까울 수록 높은 수치) 예시 NMS(Non-Maximum Suppression, 비최댓값 억제) 확률이 가장 높은 상자와 겹치는 상자들을 제거하는 과정 최댓값을 갖지 않는 상자들을 제거 과정 확률 기준으로 모든 상자를 정렬하고 먼저 가장 확률이 높은 상자를 취함 각 상자에 대해 다른 모든 상자와의 IOU를 계산 특정 임곗값을 넘는 상자는 제거 모델 성능 평가정밀도(Precision)와 재현율(Recall) 일반적으로 객체 탐지 모델 평가에 사용되지는 않지만, 다른 지표를 계산하는 기본 지표 역할을 함 True Positives(TP): 예측이 동일 클래스의 실제 상자와 일치하는지 측정 False Positives(FP): 예측이 실제 상자와 일치하지 않는지 측정 False Negatives(FN): 실제 분류값이 그와 일치하는 예측을 갖지 못하는지 측정 모델이 안정적이지 않은 특징을 기반으로 객체 존재를 예측하면 거짓긍정(FP)이 많아져서 정밀도가 낮아짐 모델이 너무 엄격해서 정확한 조건을 만족할 때만 객체가 탐지된 것으로 간주하면 거짓부정(FN)이 많아져서 재현율이 낮아짐 정밀도-재현율 곡선(Precision-Recall Curve) 신뢰도 임계값마다 모델의 정밀도와 재현율을 시각화 모든 bounding box와 함께 모델이 예측의 정확성을 얼마나 확실하는지 0 ~ 1사이의 숫자로 나타내는 신뢰도를 출력 임계값 T에 따라 정밀도와 재현율이 달라짐 임계값 T 이하의 예측은 제거함 T가 1에 가까우면 정밀도는 높지만 재현율은 낮음 놓치는 객체가 많아져서 재현율이 낮아짐. 즉, 신뢰도가 높은 예측만 유지하기때문에 정밀도는 높아짐 T가 0에 가까우면 정밀도는 낮지만 재현율은 높음 대부분의 예측을 유지하기때문에 재현율은 높아지고, 거짓긍정(FP)이 많아져서 정밀도가 낮아짐 예를 들어, 모델이 보행자를 탐지하고 있으면 특별한 이유없이 차를 세우더라도 어떤 보행자도 놓치지 않도록 재현율을 높여야 함 모델이 투자 기회를 탐지하고 있다면 일부 기회를 놓치게 되더라도 잘못된 기회에 돈을 거는 일을 피하기 위해 정밀도를 높여야 함 AP (Average Precision, 평균 정밀도) 와 mAP(mean Average Precision) 곡선의 아래 영역에 해당 항상 1x1 정사각형으로 구성되어 있음즉, 항상 0 ~ 1 사이의 값을 가짐 단일 클래스에 대한 모델 성능 정보를 제공 전역 점수를 얻기위해서 mAP를 사용 예를 들어, 데이터셋이 10개의 클래스로 구성된다면 각 클래스에 대한 AP를 계산하고, 그 숫자들의 평균을 다시 구함 mAP 사용 최소 2개 이상의 객체를 탐지하는 대회인 PASCAL Visual Object Classes와 Common Objects in Context(COCO)에서 mAP가 사용됨 COCO 데이터셋이 더 많은 클래스를 포함하고 있기 때문에 보통 Pascal VOC보다 점수가 더 낮게 나옴 객체 탐지 (Object Detection)의 역사 RCNN (2013) Rich feature hierarchies for accurate object detection and semantic segmentation (https://arxiv.org/abs/1311.2524) 물체 검출에 사용된 기존 방식인 sliding window는 background를 검출하는 소요되는 시간이 많았는데, 이를 개선시킨 기법으로 Region Proposal 방식 제안 매우 높은 Detection이 가능하지만, 복잡한 아키텍처 및 학습 프로세스로 인해 Detection 시간이 매우 오래 걸림 SPP Net (2014) Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition (https://arxiv.org/abs/1406.4729) RCNN의 문제를 Selective search로 해결하려 했지만, bounding box의 크기가 제각각인 문제가 있어서 FC Input에 고정된 사이즈로 제공하기 위한 방법 제안 SPP은 RCNN에서 conv layer와 fc layer사이에 위치하여 서로 다른 feature map에 투영된 이미지를 고정된 값으로 풀링 SPP를 이용해 RCNN에 비해 실행시간을 매우 단축시킴 Fast RCNN (2015) Fast R-CNN (https://arxiv.org/abs/1504.08083) SPP layer를 ROI pooling으로 바꿔서 7x7 layer 1개로 해결 SVM을 softmax로 대체하여 Classification 과 Regression Loss를 함께 반영한 Multi task Loss 사용 ROI Pooling을 이용해 SPP보다 간단하고, RCNN에 비해 수행시간을 많이 줄임 Fater RCNN(2015) Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks (https://arxiv.org/abs/1506.01497) RPN(Region proposal network) + Fast RCNN 방식 Selective Search를 대체하기 위한 Region Proposal Network구현 RPN도 학습시켜서 전체를 end-to-end로 학습 가능 (GPU사용 가능) Region Proposal를 위해 Object가 있는지 없는지의 후보 Box인 Anchor Box 개념 사용 Anchor Box를 도입해 FastRCNN에 비해 정확도를 높이고 속도를 향상시킴 SSD (2015) SSD: Single Shot MultiBox Detector (https://arxiv.org/abs/1512.02325) Faster-RCNN은 region proposal과 anchor box를 이용한 검출의 2단계를 걸치는 과정에서 시간이 필요해 real-time(20~30 fps)으로는 어려움 SSD는 Feature map의 size를 조정하고, 동시에 앵커박스를 같이 적용함으로써 1 shot으로 물체 검출이 가능 real-time으로 사용할 정도의 성능을 갖춤 (30~40 fps) 작은 이미지의 경우에 잘 인식하지 못하는 경우가 생겨서 data augmentation을 통해 mAP를 63에서 74로 비약적으로 높임 RetinaNet (2017) Focal Loss for Dense Object Detection (https://arxiv.org/abs/1708.02002) RetinaNet이전에는 1-shot detection과 2-shot detection의 차이가 극명하게 나뉘어 속도를 선택하면 정확도를 trade-off 할 수 밖에 없는 상황 RetinaNet은 Focal Loss라는 개념의 도입과 FPN 덕분에 기존 모델들보다 정확도도 높고 속도도 여타 1-shot detector와 비견되는 모델 Detection에선 검출하고 싶은 물체와 (foreground object) 검출할 필요가 없는 배경 물체들이 있는데 (background object) 배경 물체의 숫자가 매우 많을 경우 배경 Loss를 적게 하더라도 숫자에 압도되어 배경의 Loss의 총합을 학습해버림 (예를 들어, 숲을 배경으로 하는 사람을 검출해야하는데 배경의 나무가 100개나 되다보니 사람의 특징이 아닌 나무가 있는 배경을 학습해버림) Focal Loss는 이런 문제를 기존의 crossentropy 함수에서 (1-sig)을 제곱하여 background object의 loss를 현저히 줄여버리는 방법으로 loss를 변동시켜 해결 Focal Loss를 통해 검출하고자 하는 물체와 관련이 없는 background object들은 학습에 영향을 주지 않게 되고, 학습의 다양성이 더 넓어짐 (작은 물체, 큰 물체에 구애받지 않고 검출할 수 있게됨) 실제로 RetinaNet은 object proposal을 2000개나 실시하여 이를 확인 Mask R-CNN (2018) Mask R-CNN (https://arxiv.org/pdf/1703.06870.pdf) YOLO (2018) YOLOv3: An Incremental Improvement (https://arxiv.org/abs/1804.02767) YOLO는 v1, v2, v3의 순서로 발전하였는데, v1은 정확도가 너무 낮은 문제가 있었고 이 문제는 v2까지 이어짐 엔지니어링적으로 보완한 v3는 v2보다 살짝 속도는 떨어지더라도 정확도를 대폭 높인 모델 RetinaNet과 마찬가지로 FPN을 도입해 정확도를 높임 RetinaNet에 비하면 정확도는 4mAP정도 떨어지지만, 속도는 더 빠르다는 장점 RefineDet (2018) Single-Shot Refinement Neural Network for Object Detection (https://arxiv.org/pdf/1711.06897.pdf) M2Det (2019) M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network (https://arxiv.org/pdf/1811.04533.pdf) EfficientDet (2019) EfficientDet: Scalable and Efficient Object Detection (https://arxiv.org/pdf/1911.09070v1.pdf) YOLOv4 (2020) YOLOv4: Optimal Speed and Accuracy of Object Detection (https://arxiv.org/pdf/2004.10934v1.pdf) YOLOv3에 비해 AP, FPS가 각각 10%, 12% 증가 YOLOv3와 다른 개발자인 AlexeyBochkousky가 발표 v3에서 다양한 딥러닝 기법(WRC, CSP …) 등을 사용해 성능을 향상시킴 CSPNet 기반의 backbone(CSPDarkNet53)을 설계하여 사용 YOLOv5 (2020) YOLOv4에 비해 낮은 용량과 빠른 속도 (성능은 비슷) YOLOv4와 같은 CSPNet 기반의 backbone을 설계하여 사용 YOLOv3를 PyTorch로 implementation한 GlennJocher가 발표 Darknet이 아닌 PyTorch 구현이기 때문에, 이전 버전들과 다르다고 할 수 있음 이후 수 많은 YOLO 버전들이 탄생 Object Detection 분야의 논문들이 계속해서 나오고 있음 " }, { "title": "[SQL] SQL 기본 문법 정리", "url": "/posts/SQL-%EA%B8%B0%EB%B3%B8-%EB%AC%B8%EB%B2%95/", "categories": "SQL", "tags": "SQL", "date": "2022-04-05 19:36:02 +0900", "snippet": "SQL 기본 문법 정리 SELECT# 기본 구조SELECT 필드이름 FROM 테이블# 여러 필드 조회SELECT 필드이름1, 필드이름2 FROM 테이블# 모든 필드 조회SELECT * FROM 테이블# 중복데이터 제외하고 조회SELECT DISTINCT 필드이름 FROM 테이블# 조건식 사용SELECT * FROM 테이블 WHERE 필드이름=0# 여러 조건식SELECT *FROM 테이블WHERE 필드이름1=0AND 필드이름2=0OR 필드이름3=0# 조건식 종류WHERE 필드이름 BETWEEN 0 AND 100WHERE 필드이름 NOT BETWEEN 0 AND 100WHERE 필드이름 IN (0, 10, 100)WHERE 필드이름 NOT IN (0, 10, 100)WHERE 필드이름 IS NULLWHERE 필드이름 NOT IS NULLWHERE 필드이름 LIKE '홍__'WHERE 필드이름 NOT LIKE '홍__'WHERE 필드이름 LIKE '홍%'WHERE 필드이름 NOT LIKE '홍%'# 특정 필드 기준으로 정렬SELECT 필드이름 FROM 테이블 ORDER BY 필드이름# 정렬 기준 여러개SELECT 필드이름FROM 테이블ORDER BY 필드이름1, 필드이름2 DESC, 필드이름3 ASC# 내부 조인한 결과 출력SELECT 테이블1.필드이름FROM 테이블1, 테이블2WHERE 테이블1.필드이름 = 테이블2.필드이름# 별칭을 이용해 코드 간소화 (위 코드와 동일)SELECT A.필드이름FROM 테이블1 A, 테이블2 BWHERE A.필드이름 = B.필드이름# 외부 조인한 결과 출력SELECT A필드이름FROM 테이블1 A, 테이블2 BWHERE A.필드이름 = B.필드이름(+)# 집합 연산을 이용해 결과 출력SELECT 필드이름FROM 테이블1UNION (또는 UNION ALL, MINUS, INTERSET)SELECT 필드이름FROM 테이블2# 서브 쿼리(중첩 쿼리)를 실행하는 경우_서브 쿼리 결과가 하나일 때SELECT 필드이름1FROM 테이블WHERE 테이블.필드이름2 &lt;= ( SELECT 필드이름2 FROM 테이블 WHERE 조건문)# 서브 쿼리(중첩 쿼리)를 실행하는 경우_서브 쿼리 결과가 여러개일 때SELECT 필드이름1FROM 테이블WHERE 테이블.필드이름2 IN ( SELECT 필드이름2 FROM 테이블 WHERE 조건문)# IN 외에 ANY, ALL, EXIST도 쓸 수 있음 INSERTINSERT INTO 테이블(필드이름1, 필드이름2)VALUES (값1, 값2) UPDATE UPDATE 테이블 SET 필드이름1=값1, 필드이름2=값2WHERE 조건문 DELETE```DELETE FROM 테이블WHERE 조건문```" }, { "title": "[Python] Observer Pattern 정리", "url": "/posts/python-observer-pattern/", "categories": "Python", "tags": "DesignPattern", "date": "2022-04-03 20:11:10 +0900", "snippet": "Observer Pattern 옵저버 패턴은 하나의 관찰대상, 여러 개의 관찰자 구조가 필요할 때 쓰인다. 주체에 종속된 관찰자들에게 주체가 변경됨을 자동을 알리는 디자인 패턴으로,분산 이벤트 처리 시스템 구현시 사용한다. Subject 관찰 대상이 되는 객체 자신을 관찰하는 옵저버 리스트를 가지고 관리도 함 (옵저버 붙이기(attach), 제거(detach), 알리기(notfiy) 를 가짐.) Obsever Subject 를 관찰하는 객체 Subejct 가 notify 를 호출하면 Observer 의 update 도 호출됨. 즉 observer.update()에 관찰 대상이 notify 했을 때의 할 일들을 작성 활용 상황 관찰대상 - 관찰자의 구조를 가질 때 사용 이벤트 핸들러가 대표적인 옵저버 패턴의 예(이벤트 핸들러 : Observer, 이벤트 : Subject)구현 예시# 관찰 대상subject = ConcreteSubject()# 관찰할 옵저버를 만들고, 관찰 대상에 옵저버를 붙인다.observer_a = ConcreteObserverA()subject.attach(observer_a)observer_b = ConcreteObserverB()subject.attach(observer_b)# 관찰 대상은 자기 할일 함. 이때 마다 전파!subject.some_business_logic()# 관찰 대상에서 옵저버를 뗀다.subject.detach(observer_a)class Subject(): def __init__(self) -&gt; None: self._observers = [] def attach(self, observer: Observer) -&gt; None: self._observers.append(observer) def detach(self, observer: Observer) -&gt; None: self._observers.remove(observer) def notify(self) -&gt; None: for observer in self._observers: observer.update(self) def some_business_logic(self) -&gt; None: # 어떤 필요한 로직을 진행 # 이후 자신을 관찰하고 있는 옵저버들에게 알림. self.notify()class Observer(metaClass=ABCMeta): @abstractmethod def update(self, subject: Subject) -&gt; None: passclass ConcreteObserverA(Observer): def update(self, subject: Subject) -&gt; None: # 관찰 중인 대상을 파라미터로 받아, 해야하는 일 처리.class ConcreteObserverB(Observer): def update(self, subject: Subject) -&gt; None: # 관찰 중인 대상을 파라미터로 받아, 해야하는 일 처리.참고https://wikidocs.net/83755" }, { "title": "[Python] with as 구문 정리", "url": "/posts/python-with-ad/", "categories": "Python", "tags": "Python", "date": "2022-03-25 19:24:31 +0900", "snippet": "Python with ~ as 구문 with as는 파일을 열고 &gt; 쓰고 &gt; 닫기 를 자동으로 해준다. 사용법 with [expression] as [변수명] with open('textfile.txt', 'r') as file: contents = file.read()# 위 구문과 동일한 내용file = open('textfile.txt', 'r')contents = file.read()file.close() 두번째 코드를 실행한다고 할때 만약에 content = file.read() 에서 에러가 난다면 file 을 닫을 수 없다. 그러나 with 문을 사용하면 에러가 나더라도 file 을 자동으로 닫아준다.with을 class에 응용 open 함수 이외의 사용이 끝난 객체를 종료 with 구문의 표현식을 open함수 이외에 사용자가 임의로 정의한 클래스 객체로 정의, 사용시 class 내부 메소드에 enter(),exit() 메소드에 대한 내용을 입력해야 한다 객체가 실핼될 때 enter()가 자동으로 호출, 종료 될때 exit()를 호출class Withest: #초기화 메서드 정의 def __init__(self): self.temp = \"초기화 메서드\" #객체가 호출될 때 자동으로 실행 def __enter__(self): print(self.temp) return self # 반환값이 있어야 Variable을 블록내에서 사용할 수 있다 def printText(self): print(\"메소드 호출 테스트\") #with 구문 통해 객체가 종료될 때 자동으로 실행 def __exit__(self, exc_type, exc_val, exc_tb): #exc_type, exc_val, exc_tb는 with 문을 빠져나오기 이전에 예외가 발생했을 때를 나타내는 정보 #종료 구문 설정하기(세션의 종료 등) print(\"with 통해 종료\")# 객체 생성 및 with 구문 실행if __name__ = \"__main__\": withclass = Withest() with withclass as wc: wc.printText()# &gt;&gt;# 초기화 메서드# 메소드 호출 테스트# with 통해 종료" }, { "title": "[Python] Class, Object, Instance 정리", "url": "/posts/python_class-object-instance/", "categories": "Python", "tags": "Python", "date": "2022-03-22 21:12:45 +0900", "snippet": "Class, Object, Instance 개념 정리 Class 주로 어떤 틀에 비유됨, 즉 같은 무엇을 계속 만들어 내는것 클래스는 객체(Object)를 정의하고 만들기 위한 변수와 메서드의 집합 class의 객체(object)가 sw에서 실체화 되면 그것이 instanceclass car: def on(self): print('car!!')ray = car()ray.on()1) ray는 객체(object)2) ray 객체(object)는 car 클래스의 인스턴스(ray = car() 로 실체화 됨) 인스턴스(instance)라는 표현은 특정 객체가 어떤 클래스의 객체인지 관계를 중점으로 표현할 때 사용인스턴스 변수란? 인스턴스변수란 각각의 인스턴스 마다 독립한 변수 각각의 인스턴스 변수는 다른 것으로 취급하는 변수에 값을 대입해도, 인스턴스마다 각각의 값을 보존1) 인스턴스 변수의 선언과 접근 방법 일반적으로 인스턴스 변수의 생성은 생성자 클래스 init() 내부에서 이루어진다.self.인스턴스변수 = 값2) 인스턴스 변수의 사용예class Myclass: def __init__(self, text) : # 초기화 : 인스턴스 작성시에 자동적으로 호출된다. self.vlaue = text # 인스턴스 변수 value를 선언한다. def print_value(self): # 인스턴스 변수 value의 값을 표시하는 함수 print(self.value) # 인스턴스 변수 value에 접근하고 표시한다.if __name__ = \"__main__\": a = MyClass(\"123\") # 인스턴스 a를 작성 b = MyClass(\"abc\") # 인스턴스 b를 작성 print(a.value) # 123 print(b.value) # abc a.print_value() # 123 b.print_value() # abc python에서 클래스 내에 정의된 메소드로부터 인스턴스 변수로 접근하는 경우에 메소드(인스턴스 메소드)의 인수에 self를 전달하여 접근 인수 self로는 자동적으로 인스턴스 자체가 전달된다.클래스 변수란? 클래스 변수는 인스턴스 변수와 달리 모든 인스턴스 사이에 공유된 값을 가진 변수 클래스 변수는 인스턴스를 생성하는 것이 아닌 참고하는 것이 가능1) 클래스 변수의 선언과 접근방법class MyClass: 클래스변수 = 값 클래스 변수 접근 클래스.클래스변수2) 클래스 변수의 사용예class MyClass:\tvalue = \"abc\" # 클래스 변수를 선언if __name__ == \"__main__\":\tprint MyClass.value # abc 클래스의 인스턴스를 생성하는 것이 아닌 MyClass의 클래스 변수 value에 접근하여 값을 표시 클래스의 인스턴스를 생성하고 클래스 변수를 표시```pythonclass MyClass:\tvlaue = 0 # 클래스 변수를 선언def __init__(self): # 초기화 : 인스턴스 생성\tMyClass.value += 1if name == “main”:\ta = MyClass() # 인스턴스 a를 생성한다. print MyClass.vlaue # 1b = MyClass() # 인스턴스 b를 생성한다.print MyClass.value # 2 ```3) 클래스 변수 사용시 주의사항 클래스 변수에 접근할 때는 특별히 이유가 없다면 ‘인스턴스.클래스변수’ 나 ‘self.클래스변수’와 같이 접근하는 것은 피해야한다. python에는 인스턴스 변수를 인스턴스 객체로부터 생성하는 것이 가능하므로 의도치 않게 클래스 변수를 인스턴스 변수로 은폐해버리는 경우가 있다.클래스 변수 - 인스턴스 변수 차이점" }, { "title": "[Python] NameSpace 정리", "url": "/posts/python-nameSpace-%EC%A0%95%EB%A6%AC/", "categories": "Python", "tags": "Python", "date": "2022-03-19 19:40:24 +0900", "snippet": "Python NameSpace 정리 네임스페이스(namespace, 이름공간)란 프로그래밍 언어에서 특정한 객체(Object)를 이름(Name)에 따라 구분할 수 있는 범위 파이썬 내부의 모든것은 객체로 구성되며 이들 각각은 특정 이름과의 매핑 관계를 가짐 이 매핑을 포함하는 공간이 네임스페이스 프로그래밍언어에서는 네임스페이스라는 개념을 도입하여, 특정한 하나의 이름이 통용될 수 있는 범위를 제한 소속된 네임스페이스가 다르다면 같은 이름이 다른 개체를 가리키도록 하는 것이 가능Python의 네임스페이스 분류 전역 네임스페이스: 모듈별로 존재하며, 모듈 전체에서 통용될 수 있는 이름들이 소속 지역 네임스페이스: 함수 및 메서드 별로 존재하며, 함수 내의 지역 변수들의 이름들이 소속 빌트인 네임스페이스: 기본 내장 함수 및 기본 예외들의 이름들이 소속된다. 파이썬으로 작성된 모든 코드 범위가 포함파이썬의 네임스페이스 특징 네임스페이스는 딕셔너리 형태로 구현 모든 이름 자체는 문자열로 되어있고 각각은 해당 네임스페이스의 범위에서 실제 객체를 가리킨다. 이름과 실제 객체 사이의 매핑은 가변적(Mutable)이므로 런타임동안 새로운 이름이 추가될 수 있다. 다만, 빌트인 네임스페이스는 함부로 추가하거나 삭제할 수 없다. python 변수 스코프 확인# namespace_example01.pydef outer_func(): a = 20 def inner_func(): a = 30 print(\"a = %d\" % a) inner_func() print(\"a = %d\" % a)a = 10outer_func()print(\"a = %d\" % a)&gt;&gt;&gt;a = 30a = 20a = 10 맨위 outer_func가 정의되지만 인터프리터는 함수 정의부분은 정의만하고 실행하지 않음. 따라서 가장 먼저 실행되는 부분은 함수 정의 밑부분인 a = 10 a = 10가 실행되면 이 모듈의 전역 변수로 a가 추가. 그 다음으로 outer_func가 실행되서 함수 내부의 지역 변수로 또 다시 a = 20으로 선언 다음 inner_func의 정의 부분은 다시 또 뛰어넘고 inner_func가 실행 inner_func 내부에서는 지역 변수로 a = 30이 정의가 되며 여기서 a를 출력시 외부 지역 변수 및 전역 변수 a들을 모두 무시하고 현재 스코프의 지역 변수 a가 출력마찬가지로 outer_func가 실행되는 부분에서도 a는 현재 함수의 스코프의 지역 변수인 a가 출력된다. 그리고 마지막으로 전역 변수 a가 출력 NameSpace 개념을 통한 if name == ‘main‘:의 의미 현재 모듈의 네임스페이스가 __main__에 해당한다면,즉 현재 모듈이 커맨드 라인 상에서 직접 실행되는 경우에만 if문 이하를 실행하라는 의미 " }, { "title": "[Python] deepcopy - 깊은복사 정리", "url": "/posts/python-deepCopy/", "categories": "Python", "tags": "Python", "date": "2022-03-16 18:32:51 +0900", "snippet": "객체 복사 개념 파이썬에서 변수는 자신에게 대입된 객체를 가리키는 일종의 포인터 같은 존재이다. 그러므로 변수 자체는 저장공간을 할당받지 않으며 객체를 가리키는 개념이다.Mutable 객체 : 가변 속성Immutable 객체 : 불변 속성a = 1b = aprint(a, b) # 1 1b = 2print(a, b) # 1 2# int의 자료형은 Immutable하여 a,b 값이 서로 다름a = [1, 2, 3, 4]b = aprint(a, b) # [1, 2, 3, 4] [1, 2, 3, 4]# list 자료형은 Mutable하여 a,b값이 동일하게 변화 얕은 복사(Shallow Copy) 객체를 새로운 객체로 복사하지만 원본 객체의 주소값을 복사하는것 깊은 복사(Deep Copy) 전체 복사로 참조값의 복사가 아닌 참조된 객체 자체를 복사 ex) 원본 배열의 보존을 할 필요가 허다하기 때문에 이럴때는 배열을 ‘깊은 복사’ 하여야 한다. DeepCopy 예시# copy모듈 deepcopy() 이용import copya = [1, 2, 3, 4]b = ab[1] = 0print(a, b) # [1, 0, 3, 4] [1, 0, 3, 4]# !=a = [1, 2, 3, 4]b = copy.deepcopy(a)b[1] = 0print(a, b) # [1, 2, 3, 4] [1, 0, 3, 4] deepcopy로 복사된 b는 a값이 아닌 a값이 참조하는 [1,2,3,4] 자체를 참조한다 b[1] 값을 변경하면 원본 a는 그대로 이고, b값만 바뀌게 된다클래스가 가지고있는 copy() 함수 이용a = [1, 2, 3, 4]b = a.copy()b[1] = 0print(a,b) # [1, 2, 3, 4] [1, 0, 3, 4]list를 생성할 때 매개변수에 원본을 전달,혹은 생성후 원본 리스트를 확장a = [1, 2, 3, 4]b = list(a)b[1] = 0print(a,b) # [1, 2, 3, 4] [1, 0, 3, 4]a = [1, 2, 3, 4]b = []b.extend(a)b[1] = 0print(a,b) # [1, 2, 3, 4] [1, 0, 3, 4]리스트 슬라이싱a = [1, 2, 3, 4]b = a[:]b[1] = 0print(a,b) # [1, 2, 3, 4] [1, 0, 3, 4]배열요소를 통한 접근 복사a = [1, 2, 3, 4]b = [i for i in a]b[1] = 0print(a,b) # [1, 2, 3, 4] [1, 0, 3, 4]a = [1, 2, 3, 4]b = []for i in range(len(a)): b.append(a[i])b[1] = 0print(a,b) # [1, 2, 3, 4] [1, 0, 3, 4]※ 주의 :리스트 슬라이싱이나 제네릭 copy의 copy() 메소드에서 리스트가 오브젝트를 포함할 경우 그 오브젝트들은 얕은복사됨※ 참고 : 처리속도는 리스트 슬라이싱이 가장 빠르고 copy 모듈의 deepcopy() 메소드가 가장 느리다" }, { "title": "[Python] weakref 약한참조 사용 및 python 메모리 확인", "url": "/posts/python-weakref/", "categories": "Python", "tags": "Python", "date": "2022-03-15 21:40:02 +0900", "snippet": "weakref 정리 파이썬은 Objective-C와 비슷하게 참조 카운트(Reference Count)기반의 자동 메모리 관리 모델을 따르고 있다. 파이썬의 모든 변수는 값을 담는 영역이 아니라 객체에 바인딩 되는 이름이다.→ 객체와 이름이 바인딩 되면, 해당 객체는 그 이름에 의해 참조 되고 참조 카운트를 1 증가시킨다. 그 이름이 더 이상 해당 객체를 가리키지 않게 되는 경우, (변수 스코프를 벗어나거나 다른 객체에 바인딩 되는 경우) 참조 카운트는 1이 감소→ 그 결과로 참조 카운트가 0이 되면 객체는 GC 도움 없이 즉시 파괴된다. 바인딩이란? 프로그램의 기본단위(ex 변수)에 해당 단위가 가질수 있는 속성을 연결해 주는것 python 에서 abc = 10 이라고 하면, abc 변수에 int 10이 바인딩 된것 참조 카운트 확인import sysclass RefExam(): def __init__(self): print('create object')a = RefExam()print(f'count {sys.getrefcount(a)}')b = aprint(f'count {sys.getrefcount(a)}')c = aprint(f'count {sys.getrefcount(a)}')c = 0print(f'count {sys.getrefcount(a)}')b = 0print(f'count {sys.getrefcount(a)}')\"\"\"OUT PUT:count 2count 3count 4count 3count 2\"\"\"# 맨 처음 2가 출력되는 이유는 getrefcount()의 파라미터값으로 임시 참조되기 때문객체가 참조수 0이 되거나 다른 이유로 메모리에서 해제될 때에는 해당 객체의 __del__() [소멸자] 호출(특정 클래스에서 이 메소드를 변경해서 객체가 제거되는 시점에 필요한 리소스 정리를 할 수 있다.)참조 카운트 0이 될때class Foo: def __init__(self): self.value = 1 def __del__(self): print(f'Object({id(self)}:{self.__class__}) is being destroyed.')a = Foo() # class Foo 인스턴스 생성a = 1 # a 변수에 int 1 바인딩 -&gt; Foo() 참조 카운트 -1# &gt;&gt; Object(1443682546880:&lt;class '__main__.Foo'&gt;) is being destroyed. Foo클래스를 참조하고 있는 a 변수에 int 1을 바인딩하여 Foo 클래스의 소멸자가 호출된다.a = Foo()b = Foo()a = b ## 1)# Object(1087b8192b0:&lt;class '__main__.Foo'&gt;) is being destroyed.b = 1 ## 2)a = 2 ## 3)# Object(1087b827ba8:&lt;class '__main__.Foo'&gt;) is being destroyed.1) a, b 인스턴스 생성, a변수에 b 바인딩 → 맨처음 a에 할당된 Foo()의 소멸자가 호출됨2) b변수에 int 1 바인딩, 하지만 a는 맨 처음 생성된 b 객체(Foo()가 바인딩된)를 참조 하고있으므로 b에 바인딩 되었던 Foo()는 사라지지 않음3) a변수에 int 2가 바인딩 되어 a가 참조하던 Foo()의 소멸자가 호출됨WeakRef 약한 참조 클래스 인스턴스의 속성이 다른 클래스의 인스턴스를 참조하거나, 동일 클래스의 다른 인스턴스를 참조할 가능성이 높다면 이는 메모리 누수가 발생할 가능성이 매우 높은 지점 약한 참조는 대상 객체를 참조는 하지만 reference count(참조 카운트)를 올리지 않는다. 약한 참조는 weakref 모듈의 ref 클래스를 통해 생성한다. 사용 예시import weakrefa_set = {0,1}a_ref = weakref.ref(a_set) # 1)print(a_ref)print(a_ref())a_set = {2, 3, 4} # 2)print(a_ref()) # 3)print(a_ref() is None)# &gt;&gt;&gt;# &lt;weakref at 0x000001DD6BBEA810; to 'set' at 0x000001DD6BD7D740&gt;# {0, 1}# None# True1) a_ref 변수에 a_set을 할당한다. a_set의 {1,2} 값을 a_ref가 참조2) a_set 변수에 새로운 값 {2,3,4}를 할당한다. 1)에서의 a_ref가 더이상 {0,1}을 참조하지 않는다.3) a_ref()는 참조값이 없어져 None을 반환한다.약한 참조를 써야 하는 곳 한 개 이상의 객체가 참조 순환 고리를 만드는 경우 메모리 누수를 방지하기 위해 주로 사용 용량이 큰 객체를 자주 사용하거나, 쉽게 만들 수 있을 때 caching에 사용하면 효과적 : 대용량 이미지 데이터를 가지고 있을 때, 메모리 관리를 편하게 하기위해 (local에 제한을 둠)" }, { "title": "[Python] Numpy 기본 문법", "url": "/posts/python-numpy-%EA%B8%B0%EB%B3%B8%EB%AC%B8%EB%B2%95/", "categories": "Python", "tags": "Python, Numpy", "date": "2022-03-11 19:21:12 +0900", "snippet": "Numpy python에서 벡터,행렬등 수치 연산을 수행하는 선형대수(Linear algebra) 라이브러리 내부적으로 C로 구현되었으며 연산이 빠르다. N차원 배열(array)객체이며 모든 배열의 값이 기본적으로 같은 타입이어야 한다.import numpy as npimport numpy.random as npa = np.arrange(15).reshape(3,5)print(a)# [[ 0 1 2 3 4]# [ 5 6 7 8 9]# [10 11 12 13 14]]3행 5열의 arraynumpy.ndarray 의 대표적인 속성값 ndarray.shape : 배열의 각 축(axis)의 크기 ndarray.ndim : 축의 갯수(Dimension) ndarray.dtype : 각 요소(Element)의 타입 ndarray.itemsize : 각 요소(Element)의 타입의 bytes 크기 ndarray.size : 전체 요소(Element)의 개수배열 생성 - array creation a = np.array( [2, 3, 4] ) np.zeros(shape) : 0으로 구성된 N차원 배열 생성 np.ones(shape) : 1로 구성된 N차원 배열 생성 np.empty(shape) : 초기화되지 않은 N차원 배열 생성np.arrange() 와 np.linspace()를 이용하여 연속적인 데이터 생성 np.arange() : N 만큼 차이나는 숫자 생성 np.linspace() : N 등분한 숫자 생성# 10이상 30미만까지 5씩 차이나는 배열 생성print(np.arrange(10,30,5))[10 15 20 25]# 0 ~ 99 까지 100등분x = np.linspace(0, 99, 100)print(x)# [ 0. 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17.# 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35.# 36. 37. 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49. 50. 51. 52. 53.# 54. 55. 56. 57. 58. 59. 60. 61. 62. 63. 64. 65. 66. 67. 68. 69. 70. 71.# 72. 73. 74. 75. 76. 77. 78. 79. 80. 81. 82. 83. 84. 85. 86. 87. 88. 89.# 90. 91. 92. 93. 94. 95. 96. 97. 98. 99.]배열 출력 - print arrays3D 배열은 2차원 배열이 N개 출력되는 형식으로 나타남b = np.arange(12).reshape(4,3)print(b)# [[ 0 1 2]# [ 3 4 5]# [ 6 7 8]# [ 9 10 11]]c = np.arange(24).reshape(2,3,4)print(c)# [[[ 0 1 2 3]# [ 4 5 6 7]# [ 8 9 10 11]]## [[12 13 14 15]# [16 17 18 19]# [20 21 22 23]]]# reshape()을 통해 데이터는 유지한채 차원만 변경가능# [10000] 배열을 [100, 100] 배열로 변경np.arange(10000).reshape(100,100)Numpy 연산numpy에서 수치연산은 기본적으로 숫자 각각의 요소에 연산 적용a = np.array( [20,30,40,50] )b = np.arange( 4 )print(b)# [0 1 2 3]# a에서 b에 각각의 원소를 -연산c = a-bprint(c)# [20 29 38 47]# b 각각의 원소에 제곱 연산print(b**2)# [0 1 4 9]# a 각각의 원소에 *10 연산print(10*np.sin(a))# [ 9.12945251 -9.88031624 7.4511316 -2.62374854]# a 각각의 원소가 35보다 작은지 Boolean 결과print(a&lt;35)# [ True True False False]2차원 배열을 행렬이라고 볼때, 여러가지 곱셈법 : 각각의 원소끼리 곱셈 @ : 행렬 곱셈 .dot() : 행렬 내적numpy 내장함수.sum(): 모든 요소의 합.min(): 모든 요소 중 최소값.max(): 모든 요소 중 최대값.argmax(): 모든 요소 중 최대값의 인덱스.cumsum(): 모든 요소의 누적합Numpy 차원 변경 함수broadcasting rulesnumpy에서 array 연산시 편리성을 위해 shape가 다른 np.array끼리 연산을 지원해주기 위한 기법np.array([1,2,3,4,5]) * 2# 결과# [2,4,6,8,10]#내부적 수행 과정# → np.array([1,2,3,4,5]) * np.array([2,2,2,2,2])차원(ndim)이 같고, 각 축(axis)의 값이 같거나 1일 경우 연산이 가능print(np.arange(4) * 2)# [0 2 4 6]print(np.ones((3,4)) * np.arange(4))# [[0. 1. 2. 3.]# [0. 1. 2. 3.]# [0. 1. 2. 3.]]print(np.arange(3).reshape((3,1)) * np.arange(3))# [[0 0 0]# [0 1 2]# [0 2 4]]Numpy-공식문서" }, { "title": "[Python] OOP(Object Oriented Programming) 기본 개요", "url": "/posts/python-oop-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EC%9A%94/", "categories": "Python", "tags": "Python, OOP", "date": "2022-03-08 19:11:02 +0900", "snippet": "Object Oriented Programming class(설계도), object(객체), attribute(변수), method(함수)# 파이썬에서 모든 attribute, method는 기본적으로 public 즉 클래스 외부에서 attribute, method 접근 가능# publicclass Quadrangle: def __init__(self, width, height, color): self.width = width self.height = height self.color = color def get_area(self): return self.width * self.height def set_area(self, width, height): self.width = width self.height = heightsquare = Quadrangle(5,5,'blue')square.widthdir(square)# 내부 구조에 method가 전부 포함 되어 있음['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'color', 'get_area', 'height', 'set_area', 'width'] # protected'''- python에서 해당 속성의 앞에 _(single underscore) 를 붙여서 표시만 함- 실제 제약되진 않고 일종의 경고 표시로 사용'''class Quadrangle2: def __init__(self, width, height, color): self.width = width self.height = height self.color = color def _set_area(self, width, height): self._width = width self._height = heightClass Inheritance(상속) abstraction : 여러 클래스에 중복되는 속성, 메서드를 하나의 기본 클래스로 작성하는 작업 inheritance : 기본 클래스의 공통 기능을 물려받고, 다른 부분만 추가 또는 변경하는것 ( 상위 : parent, super, base class / 하위 : child, sub, derived class )class Figure: def __init__(self, name, color) : self.__name = name self.__color = colorclass Quadrangle(Figure): def set_area(self, width, height) : self.__width = width self.__height = height def get_info(self): print(self.name, self.color, self.__width * self.__height)square = Quadrangle('square','blue')square.set_area(5,5)square.get_info()'''double underscore 속성으로 접근이 안되어 error 발생''' class Figure: def __init__(self, name, color) : self.name = name self.color = colorclass Quadrangle(Figure): def set_area(self, width, height) : self.__width = width self.__height = height def get_info(self): print(self.name, self.color, self.__width * self.__height)square = Quadrangle('square','blue')square.set_area(5,5)square.get_info()-&gt; square blue 25클래스 변수 : 클래스 정의에서 메서드 밖에 존재 하는 변수 해당 클래스를 사용하는 모두에게 공용으로 사용되는 변수 클래스 변수는 클래스 내외부에서 ‘클래스명.변수명’ 으로 엑세스 가능인스턴스 변수 : 클래스 정의의 메서드 안에서 사용되면서 “self.변수명” 처럼 사용되는 변수 각 객체별로 서로 다른 값을 가짐 클래스 내부에서는 self.인스턴스변수명 을 사용하여 엑세스, 클래스 밖에서는 객체명.인스턴스변수명 으로 엑세스class Figure: count = 0 # 클래스 변수 # 생성자(initializer) def __init__(self, width, height): # self.* : 인스턴스변수 self.width = width self.height = height # 클래스 변수 접근 예 Figure.count += 1 def __del__(self): Figure.count -= 1figure2 = Figure(2, 3)Figure.countfigure1 = Figure(2, 3)print(Figure.count)instance method : 해당 객체 안에서 호출 (지금까지 다룬 self.메서드명을 의미함) 해당 메서드를 호출한 객체에만 영향을 미침 객체 속성에 접근 가능static method : 객체와 독립적이지만, 로직상 클래스내에 포함되는 메서드 self 파라미터를 갖고 있지 않음 객체 속성에 접근 불가 정적 메서드는 메서드 앞에 @staticmethod 라는 Decorator를 넣어야 함 클래스명.정적메서드명 or 객체명.정적메서드명 둘 다 호출 가능class Figure : # 생성자 def __init__(self,width, height): self.width = width self.height = height #메서드 def calc_area(self): return self.width * self.height #정적 메서드 (Figure에 너비와 높이가 같은 도형은 정사각형임을 알려주는 기능) @staticmethod def is_square(rect_width, rect_height): if rect_width == rect_height: return \"정사각형이 될 수 있는 너비/높이\" else: return \"될수 없습니다.\"figure1 = Figure(2,3)print(figure1.is_square(5,5))print(Figure.is_square(3,5))-&gt;정사각형이 될 수 있는 너비/높이될수 없습니다." }, { "title": "[Python] List Comprehension, 정렬 기본 문법 정리", "url": "/posts/python-%EC%A0%95%EB%A0%AC-%EB%AC%B8%EB%B2%95-list-comprehension/", "categories": "Python", "tags": "Python, List Comprehension", "date": "2022-03-01 15:14:00 +0900", "snippet": "Python List Comprehension 리스트를 초기화 하는 방법중 하나로 대괄호 안에([]) 조건문과 반복문을 넣는 방식으로 리스트를 초기화array = [i for i in range(21) if i%2==0]array= [i*i for i in range(1,9) if i%2==0]print(array)﻿[4, 16, 36, 64] N*M 크기의 2차원 리스트 초기화n=3m=4array=[[0]*m for _ in range(n)] #﻿ 단순 반복시 i를 _로 대체 가능'print(array) 2차원 리스트를 초기화 할때는 반드시 리스트 컴프리헨션을 이용. 다음과 같이 초기화 할 시 의도하지 않은 결과가 나올 수 있다.array =[[0]*m]*nprint(array)array[1][1]=5print(array)[[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]][[0, 5, 0, 0], [0, 5, 0, 0], [0, 5, 0, 0]] 이는 내부적으로 포함된 3개의 리스트가 모두 동일한 객체에 대한 3개의 래퍼런스로 인식되기 때문 python 정렬 기본 문법a=[1,4,3]print('기본리스트 : ',a)#리스트에 원소 삽입a.append(2)print(\"삽입 : \",a)#오름차순 정렬a.sort()print(\"오름차순 정렬: \",a)#내림차순 정렬a.sort(reverse=True)print(\"내림차순 정렬 : \",a)#리스트 원소 뒤집기a.reverse()print(\"원소 뒤집기 : \",a)# 특정 인덱스에 데이터 추가 (해당 자리에 넣고 다른것 뒤로 밀어냄)a.insert(2,3)print(\"인덱스 2에 3추가 \",a)#특정 값인 데이터 개수 세기print(\"값이 3인 데이터 개수 : \", a.count(3))a.remove(1)print(\"값이 1인 데이터 삭제 : \",a)기본리스트 : [1, 4, 3]삽입 : [1, 4, 3, 2]오름차순 정렬: [1, 2, 3, 4]내림차순 정렬 : [4, 3, 2, 1]원소 뒤집기 : [1, 2, 3, 4]인덱스 2에 3추가 [1, 2, 3, 3, 4]값이 3인 데이터 개수 : 2값이 1인 데이터 삭제 : [2, 3, 3, 4]#insert 함수는 원소 삽입후 위치를 조정하므로 append 함수보다 동작이 느리다. 특정한 원소값 제거a= [1,2,3,4,5,5,5]remove_set = {3,5}#remove_set에 포함되지 않은 값만을 저장result = [i for i in a if i not in remove_set]print(result)[1, 2, 4]Tuple 튜플은 한 번 선언된 값을 변경할 수 없다. 리스트는 대괄호[], 튜플은 소괄호() 튜플 자료형은 그래프 알고리즘을 구현시 자주 사용 ex) 다익스트라 최단 경로 알고리즘, 알고리즘 → 우선순위 큐에 한 번 들어간 값은 변경되지 않는다.Dictionary 키(key)와 값(Value)의 쌍을 데이터로 가지는 자료형data= dict()data['사과']= \"Apple\"data['바나나']='Banana'data['코코넛']= 'coconut'print(data)if '사과' in data: print(\"'사과'를 키로 가지는 데이터가 존재합니다.\"){'사과': 'Apple', '바나나': 'Banana', '코코넛': 'coconut'}'사과'를 키로 가지는 데이터가 존재합니다.Set 집합(set)을 처리하기 위한 자료형 중복을 혀용하지 않음 순서가 없다. → 사전 자료형과 집합 자료형은 순서가 없으므로 인덱싱으로 값을 얻을 수 없다.#집합 자료형 초기화 방법 - 1data = set([1,1,2,3,4,4,5])print(data)#집합 자료형 초기화 방법 - 2data = {1,1,2,3,4,4,5}print(data){1, 2, 3, 4, 5}{1, 2, 3, 4, 5}# 집합 자료형 연산, 관련 함수#합집합 : | , 교집합 : &amp; , 차집합 : -# 집합 자료형 관련 함수 : remove(),updata()data={1,2,3}print(data)#새로운 원소 추가data.add(4)print(data)#새로운 원소 여러 개 추가data.update([5,6])print(data)#특정한 값을 갖는 원소 삭제data.remove(3)print(data){1, 2, 3}{1, 2, 3, 4}{1, 2, 3, 4, 5, 6}{1, 2, 4, 5, 6}" }, { "title": "[Python] 특징 및 개요", "url": "/posts/python-%ED%8A%B9%EC%A7%95-%EA%B0%9C%EC%9A%94/", "categories": "Python", "tags": "Python", "date": "2022-02-28 18:05:08 +0900", "snippet": "python 특징특징 1. 인터프리터 언어 파이썬은 컴파일 과정 없이 인터프리터(Interpreter, 해석기)가 소스 코드를 한 줄씩 읽어 들여 곧바로 실행하는 스크립트 방식 컴파일 과정이 필요하지 않아 실행 결과를 바로 확인하고 수정하면서 손쉽게 코드를 작성할 수 있다. 컴파일 언어 : ‘컴파일’ 과정을 통해 프로그래머가 작성한 코드를 기계어로 번역하여 실행 스크립트 언어 : 별도의 ‘컴파일’ 과정 없이 인터프리터가 소스 코드를 한 줄씩 읽어가며 바로 실행하는 언어를 의미특징 2. 동적 타이핑(Dynamic typing) 변수의 자료형을 지정하지 않고 단순히 선언하는 것만으로도 값을 지정 이때 변수의 자료형은 코드가 실행되는 시점에 결정, 자료형 변환 시 번거로운 과정을 거치지 않아도 된다는 장점이 있지만, 코드 실행도중 예상하지 못한 타입으로 인한 에러가 발생할 수 있는 특징이 있다.특징 3. 플랫폼 독립적(Platform-independent)파이썬은 리눅스(Linux), 유닉스(Unix), 윈도우즈(Windows), 맥(Mac) 등 대부분의 운영체제(Operating System, OS)에서 모두 동작가능.운영체제별로 컴파일할 필요가 없기 때문에 한 번 소스 코드를 작성하면 어떤 운영체제에서든 활용이 가능하다.특징 4. 높은 확장성 및 이식성 파이썬은 대표적인 글루(Glue) 언어(혹은 접착제 언어)에 해당한다. 다른 언어나 라이브러리에 쉽게 접근해 연동할 수 있음. 높은 성능의 애플리케이션 개발이 필요한 경우 C/C++과 같은 언어를 파이썬과 결합해 사용 가능 이 경우 애플리케이션의 성능을 보장하며 스크립트 언어의 장점 또한 함께 누릴 수 있다. Python 활용 사례Google(구글) Google(구글)은 백엔드에 C++과 파이썬을 결합해 활용 짧은 대기 시간과 엄격한 메모리 제어가 중요한 스택에는 C++로 코드를 작성, 프로그램의 빠른 전달과 유지 관리가 필요한 부분에는 파이썬을 활용Instagram(인스타그램) Instagram은 파이썬으로 작성된 오픈 소스 웹 프레임워크 Django를 기본 서버 측 언어로 사용Netflix(넷플릭스) Netflix는 방대한 표준 라이브러리, 간결하고 깔끔한 구문, 대규모 커뮤니티, 풍부한 타사 라이브러리 등을 이유로 파이썬을 자사 서비스에 적극적으로 활용Spotify(스포티파이) 음악 스트리밍 및 미디어 서비스 제공 업체 Spotify의 앱은 Python을 활용해 빌드됨. Spotify 백엔드의 80%가 파이썬으로 작성Dropbox(드롭박스) 클라우드에 사진, 문서, 등의 파일 보관 및 공유 서비스를 제공하는 플랫폼 Dropbox는 외부 오픈 소스 코드와 자체 작성한 코드 모두에 파이썬을 사용 Dropbox는 크로스 플랫폼 지원, 가독성, 학습 용이성 등 파이썬이 지닌 장점 덕에 빠르게 서비스를 구현할 수 있었다고 밝혔습니다. 객체 지향 언어 : 객체 지향 프로그래밍은 컴퓨터 프로그램을 명령어의 목록으로 보는 시각에서 벗어나 여러 개의 독립된 단위, 즉 “객체”들의 모임으로 파악하고자 하는 것이다. 각각의 객체는 메시지를 주고받고, 데이터를 처리할 수 있다.-&gt; (python,java)​ 절차 지향 언어 : 프로그램을 작성할 때 실행 순서를 지정하게 되는 프로그램 작성 언어. 문제의 해결 순서와 절차의 표현과 해결이 쉽도록 설계된 프로그램 언어로서 고수준 언어에는 C 언어, 파스칼, 코볼, 포트란, 알골, PL/1 등이 있다. 인터프리터 : 프로그램을 한단계씩 해석하여 실행, 1:1 대화형식 컴파일 : java,c,c++ 완성된 코드를 컴퓨터가 이해 할 수 있는 기계 언어로 한번에 변환" } ]
